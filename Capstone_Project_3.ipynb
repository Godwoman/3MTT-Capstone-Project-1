{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1H6zTdsr9J_q3iutxND_v2BoFUXMa2Apu",
      "authorship_tag": "ABX9TyOfd/cYi1HKaJ3EeHfrc2+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Godwoman/3MTT-Capstone-Project-1/blob/main/Capstone_Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC-rdxxlGEpt",
        "outputId": "38dc25f4-d49f-4a0b-c7fb-5d1c26a5150f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "# prompt: how do i install open cv\n",
        "\n",
        "!pip install opencv-python\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python numpy scipy\n",
        "!pip install opencv-contrib-python\n",
        "!pip install filterpy\n",
        "!pip install torch torchvision\n",
        "!pip install flask\n",
        "!pip install pandas matplotlib seaborn"
      ],
      "metadata": {
        "id": "8fWo2NQzHaRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6007ac4c-4efc-4f6a-f61f-cc756c720b2e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.26.4)\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from filterpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from filterpy) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.16.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=5a3ccb5821b75c0f44083660ac95eeed8288858a85cfe3f1023f6824e98343a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "kU5goOXc5utJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory called 'frames'\n",
        "!mkdir file_dir"
      ],
      "metadata": {
        "id": "7TgyR2Pu7dpi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls # confirm is what created"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-_SR0zdAY4i",
        "outputId": "d442c4f3-4b6e-4110-f28f-dd44c973f203"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  file_dir  frames  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/drive/MyDrive/'\n",
        "print(os.listdir(root_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPSgso85Awq8",
        "outputId": "9ec2b661-05cf-4c26-82fe-56605c5bcdce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['12686755427-332106661-ticket.pdf', 'Mindset Series - Law of Rubber Band.gslides', 'Ochanyas graduation ', \"Celestina Agbo's RESUMÉ.pdf\", 'RESUMÉ.pdf', \"1_Celestina Agbo's Result.jpg\", \"Celestina Agbo's NYSC Certificate.pdf\", 'CertificateOfCompletion_Career_Essentials_in_Generative_AI_by_Microsoft_and_LinkedIn_(1)[1].pdf', 'Alison_certificate_diploma_in_human_resources[1].pdf', 'Alison_certificate_diploma_in_operations_management[1].pdf', 'Alison_certificate_diploma_in_customer_service[1].pdf', 'WEEK 2 ASSIGNMENT.docx', 'Week 1 Assignment.docx', 'WEEK 3 ASSIGNMENT.gdoc', 'WEEK  4  ASSIGNMENT.gdoc', ' Reume for Reliance Health .gdoc', ' Reume for Reliance Health .docx', \"Celestina Agbo's Resume.docx\", 'Copy of Week 1: Welcome Video Transcript.gdoc', 'Celestina`s Intro.MOV', '3mtt', 'Job search', 'Untitled document.gdoc', 'ALX', 'WEEK 5 ASSIGNMENT.gdoc', 'W3SCHOOLS - MACHINE LEARNING', 'WEEK 6 ASSIGNMENT.gdoc', 'WEEK 7 ASSIGNMENT.gdoc', 'Week 8 Assignment.gdoc', 'WEEK 9 ASSIGNMENT.gdoc', 'Colab Notebooks']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_dir = '/content/drive/MyDrive/Colab Notebooks/dense_traffic'\n",
        "print(os.listdir(file_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pD61b2cEO6I",
        "outputId": "2ed069ab-7c4b-4c63-af6a-f30e77d3545f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['images_253.jpg', 'images_427.jpg', 'images_503 (3).jpg', 'images_533.jpg', 'images_297.jpg', 'images_236 (2).jpg', 'images_278.jpg', 'images_394.jpg', 'images_448.jpg', 'images_488 (2).jpg', 'images_324.jpg', 'images_472 (2).jpg', 'images_308.jpg', 'images_280 (2).jpg', 'images_536 (2).jpg', 'images_277.jpg', 'images_301.jpg', 'images_539 (2).jpg', 'images_537.jpg', 'images_380.jpg', 'images_368.jpg', 'images_503 (4).jpg', 'images_384.jpg', 'images_437 (4).jpg', 'images_367 (2).jpg', 'images_414 (4).jpg', 'images_438 (2).jpg', 'images_276.jpg', 'images_514 (2).jpg', 'images_526 (2).jpg', 'images_328.jpg', 'images_267 (2).jpg', 'images_236.jpg', 'images_391 (3).jpg', 'images_327.jpg', 'images_461.jpg', 'images_449 (2).jpg', 'images_475 (2).jpg', 'images_459 (3).jpg', 'images_530.jpg', 'images_265 (2).jpg', 'images_473.jpg', 'images_389.jpg', 'images_491.jpg', 'images_365 (2).jpg', 'images_329.jpg', 'images_337 (2).jpg', 'images_377 (2).jpg', 'images_238.jpg', 'images_502 (3).jpg', 'images_489 (2).jpg', 'images_516 (2).jpg', 'images_401 (2).jpg', 'images_517 (2).jpg', 'images_316 (2).jpg', 'images_296.jpg', 'images_395.jpg', 'images_293 (2).jpg', 'images_356.jpg', 'images_430.jpg', 'images_419.jpg', 'images_355.jpg', 'images_510 (2).jpg', 'images_245.jpg', 'images_533 (2).jpg', 'images_463 (3).jpg', 'images_492.jpg', 'images_273 (2).jpg', 'images_403 (2).jpg', 'images_294 (3).jpg', 'images_281.jpg', 'images_522.jpg', 'images_241.jpg', 'images_412 (2).jpg', 'images_494.jpg', 'images_495.jpg', 'images_515.jpg', 'images_534.jpg', 'images_306 (2).jpg', 'images_278 (2).jpg', 'images_487 (2).jpg', 'images_503 (2).jpg', 'images_336.jpg', 'images_372.jpg', 'images_473 (2).jpg', 'images_518.jpg', 'images_499 (2).jpg', 'images_443.jpg', 'images_492 (2).jpg', 'images_387 (3).jpg', 'images_389 (2).jpg', 'images_300 (3).jpg', 'images_486.jpg', 'images_362 (2).jpg', 'images_370 (2).jpg', 'images_502 (2).jpg', 'images_391 (2).jpg', 'images_252 (2).jpg', 'images_350.jpg', 'images_246 (2).jpg', 'images_501.jpg', 'images_395 (2).jpg', 'images_303 (2).jpg', 'images_506 (3).jpg', 'images_256.jpg', 'images_431.jpg', 'images_398 (2).jpg', 'images_458 (2).jpg', 'images_258.jpg', 'images_338.jpg', 'images_511.jpg', 'images_514 (3).jpg', 'images_344 (4).jpg', 'images_384 (3).jpg', 'images_399 (2).jpg', 'images_271 (3).jpg', 'images_461 (2).jpg', 'images_323.jpg', 'images_433 (4).jpg', 'images_334 (2).jpg', 'images_385 (2).jpg', 'images_270.jpg', 'images_494 (2).jpg', 'images_242.jpg', 'images_463.jpg', 'images_432.jpg', 'images_459 (2).jpg', 'images_370.jpg', 'images_261 (2).jpg', 'images_346 (2).jpg', 'images_521 (2).jpg', 'images_287.jpg', 'images_389 (3).jpg', 'images_450.jpg', 'images_357 (2).jpg', 'images_304.jpg', 'images_388.jpg', 'images_423.jpg', 'images_268 (2).jpg', 'images_471 (3).jpg', 'images_274 (2).jpg', 'images_314.jpg', 'images_418 (2).jpg', 'images_481 (3).jpg', 'images_302 (2).jpg', 'images_261.jpg', 'images_353 (3).jpg', 'images_231.jpg', 'images_467.jpg', 'images_406 (4).jpg', 'images_263 (2).jpg', 'images_507.jpg', 'images_375 (3).jpg', 'images_374 (2).jpg', 'images_418.jpg', 'images_328 (2).jpg', 'images_294.jpg', 'images_424.jpg', 'images_277 (2).jpg', 'images_529.jpg', 'images_382.jpg', 'images_275.jpg', 'images_325.jpg', 'images_472.jpg', 'images_517 (3).jpg', 'images_527 (2).jpg', 'images_249 (2).jpg', 'images_285.jpg', 'images_400 (4).jpg', 'images_524.jpg', 'images_292.jpg', 'images_265.jpg', 'images_434.jpg', 'images_392 (2).jpg', 'images_235.jpg', 'images_508 (3).jpg', 'images_450 (2).jpg', 'images_360 (2).jpg', 'images_433 (2).jpg', 'images_280 (3).jpg', 'images_261 (3).jpg', 'images_490.jpg', 'images_347.jpg', 'images_338 (2).jpg', 'images_504 (2).jpg', 'images_442.jpg', 'images_263.jpg', 'images_531.jpg', 'images_295.jpg', 'images_378.jpg', 'images_449.jpg', 'images_441.jpg', 'images_307 (2).jpg', 'images_526.jpg', 'images_270 (2).jpg', 'images_429 (2).jpg', 'images_303 (4).jpg', 'images_386 (3).jpg', 'images_406.jpg', 'images_414 (2).jpg', 'images_487.jpg', 'images_286 (3).jpg', 'images_242 (2).jpg', 'images_388 (2).jpg', 'images_536.jpg', 'images_497 (2).jpg', 'images_283 (2).jpg', 'images_269.jpg', 'images_233 (2).jpg', 'images_498 (2).jpg', 'images_428 (2).jpg', 'images_336 (3).jpg', 'images_481 (2).jpg', 'images_247.jpg', 'images_286.jpg', 'images_397.jpg', 'images_532.jpg', 'images_512.jpg', 'images_271.jpg', 'images_288 (3).jpg', 'images_403.jpg', 'images_440 (2).jpg', 'images_359 (2).jpg', 'images_484.jpg', 'images_508 (2).jpg', 'images_514.jpg', 'images_420.jpg', 'images_387.jpg', 'images_445.jpg', 'images_416 (2).jpg', 'images_375 (2).jpg', 'images_411.jpg', 'images_360.jpg', 'images_318.jpg', 'images_246.jpg', 'images_288 (2).jpg', 'images_523.jpg', 'images_282 (2).jpg', 'images_451.jpg', 'images_471 (2).jpg', 'images_237.jpg', 'images_272.jpg', 'images_269 (2).jpg', 'images_345.jpg', 'images_314 (2).jpg', 'images_361.jpg', 'images_381.jpg', 'images_273.jpg', 'images_282.jpg', 'images_520 (2).jpg', 'images_270 (3).jpg', 'images_342.jpg', 'images_248 (2).jpg', 'images_491 (2).jpg', 'images_505.jpg', 'images_455.jpg', 'images_300 (2).jpg', 'images_366 (2).jpg', 'images_538 (2).jpg', 'images_279.jpg', 'images_358.jpg', 'images_248.jpg', 'images_351 (2).jpg', 'images_327 (2).jpg', 'images_244.jpg', 'images_431 (3).jpg', 'images_341.jpg', 'images_236 (3).jpg', 'images_399.jpg', 'images_373 (2).jpg', 'images_457 (2).jpg', 'images_260.jpg', 'images_384 (2).jpg', 'images_480 (2).jpg', 'images_360 (4).jpg', 'images_412.jpg', 'images_302.jpg', 'images_259.jpg', 'images_406 (3).jpg', 'images_380 (2).jpg', 'images_358 (2).jpg', 'images_250.jpg', 'images_429.jpg', 'images_411 (3).jpg', 'images_470.jpg', 'images_353.jpg', 'images_332.jpg', 'images_414.jpg', 'images_383.jpg', 'images_441 (2).jpg', 'images_483.jpg', 'images_433 (3).jpg', 'images_232.jpg', 'images_259 (2).jpg', 'images_393.jpg', 'images_343.jpg', 'images_364.jpg', 'images_465 (2).jpg', 'images_257 (2).jpg', 'images_344 (2).jpg', 'images_317 (2).jpg', 'images_341 (2).jpg', 'images_393 (2).jpg', 'images_520.jpg', 'images_440.jpg', 'images_376.jpg', 'images_482.jpg', 'images_439.jpg', 'images_280.jpg', 'images_416.jpg', 'images_370 (3).jpg', 'images_371.jpg', 'images_506 (2).jpg', 'images_271 (2).jpg', 'images_409 (2).jpg', 'images_506.jpg', 'images_283.jpg', 'images_421.jpg', 'images_477 (2).jpg', 'images_492 (3).jpg', 'images_425 (2).jpg', 'images_394 (2).jpg', 'images_249.jpg', 'images_485.jpg', 'images_489.jpg', 'images_232 (3).jpg', 'images_438.jpg', 'images_232 (2).jpg', 'images_524 (3).jpg', 'images_489 (3).jpg', 'images_405 (2).jpg', 'images_385.jpg', 'images_243.jpg', 'images_433.jpg', 'images_256 (2).jpg', 'images_493.jpg', 'images_489 (4).jpg', 'images_498.jpg', 'images_504.jpg', 'images_244 (2).jpg', 'images_476 (2).jpg', 'images_454.jpg', 'images_402.jpg', 'images_306.jpg', 'images_525.jpg', 'images_402 (3).jpg', 'images_456 (2).jpg', 'images_442 (2).jpg', 'images_387 (2).jpg', 'images_300.jpg', 'images_510 (3).jpg', 'images_483 (2).jpg', 'images_399 (3).jpg', 'images_479 (2).jpg', 'images_378 (2).jpg', 'images_330.jpg', 'images_386.jpg', 'images_331.jpg', 'images_317.jpg', 'images_340.jpg', 'images_465.jpg', 'images_425.jpg', 'images_471.jpg', 'images_286 (2).jpg', 'images_461 (3).jpg', 'images_509.jpg', 'images_390 (2).jpg', 'images_406 (2).jpg', 'images_479.jpg', 'images_499.jpg', 'images_253 (3).jpg', 'images_462 (2).jpg', 'images_462 (3).jpg', 'images_258 (2).jpg', 'images_349 (2).jpg', 'images_293.jpg', 'images_231 (2).jpg', 'images_536 (3).jpg', 'images_460 (2).jpg', 'images_522 (3).jpg', 'images_522 (4).jpg', 'images_517.jpg', 'images_463 (2).jpg', 'images_502.jpg', 'images_239.jpg', 'images_303 (5).jpg', 'images_419 (2).jpg', 'images_262 (2).jpg', 'images_360 (3).jpg', 'images_511 (3).jpg', 'images_400 (3).jpg', 'images_516.jpg', 'images_410.jpg', 'images_468 (2).jpg', 'images_475.jpg', 'images_377.jpg', 'images_446.jpg', 'images_400 (2).jpg', 'images_404 (2).jpg', 'images_417.jpg', 'images_407 (2).jpg', 'images_267.jpg', 'images_235 (2).jpg', 'images_336 (2).jpg', 'images_448 (3).jpg', 'images_305 (2).jpg', 'images_447 (2).jpg', 'images_381 (2).jpg', 'images_459.jpg', 'images_497.jpg', 'images_404.jpg', 'images_391.jpg', 'images_450 (3).jpg', 'images_409 (3).jpg', 'images_538.jpg', 'images_295 (2).jpg', 'images_344.jpg', 'images_457 (3).jpg', 'images_268.jpg', 'images_456.jpg', 'images_344 (3).jpg', 'images_250 (2).jpg', 'images_352.jpg', 'images_427 (2).jpg', 'images_339.jpg', 'images_532 (2).jpg', 'images_303 (3).jpg', 'images_290.jpg', 'images_363.jpg', 'images_369.jpg', 'images_359.jpg', 'images_357.jpg', 'images_481.jpg', 'images_511 (2).jpg', 'images_323 (2).jpg', 'images_348 (2).jpg', 'images_477.jpg', 'images_447 (3).jpg', 'images_436.jpg', 'images_437 (2).jpg', 'images_386 (2).jpg', 'images_390.jpg', 'images_392.jpg', 'images_347 (2).jpg', 'images_529 (2).jpg', 'images_495 (2).jpg', 'images_537 (4).jpg', 'images_335.jpg', 'images_376 (2).jpg', 'images_247 (2).jpg', 'images_460.jpg', 'images_373.jpg', 'images_291.jpg', 'images_537 (3).jpg', 'images_415.jpg', 'images_417 (2).jpg', 'images_422.jpg', 'images_478 (2).jpg', 'images_461 (4).jpg', 'images_504 (3).jpg', 'images_393 (3).jpg', 'images_315.jpg', 'images_362.jpg', 'images_334.jpg', 'images_314 (3).jpg', 'images_411 (2).jpg', 'images_426.jpg', 'images_518 (2).jpg', 'images_373 (3).jpg', 'images_284 (2).jpg', 'images_345 (2).jpg', 'images_287 (2).jpg', 'images_519.jpg', 'images_284.jpg', 'images_410 (2).jpg', 'images_513.jpg', 'images_262.jpg', 'images_274.jpg', 'images_488.jpg', 'images_521.jpg', 'images_401.jpg', 'images_310 (2).jpg', 'images_266.jpg', 'images_288.jpg', 'images_476.jpg', 'images_340 (2).jpg', 'images_367 (3).jpg', 'images_417 (3).jpg', 'images_468.jpg', 'images_484 (2).jpg', 'images_231 (3).jpg', 'images_366.jpg', 'images_321 (2).jpg', 'images_379.jpg', 'images_422 (2).jpg', 'images_371 (2).jpg', 'images_508.jpg', 'images_279 (2).jpg', 'images_539.jpg', 'images_257.jpg', 'images_496.jpg', 'images_305.jpg', 'images_448 (2).jpg', 'images_478.jpg', 'images_326 (2).jpg', 'images_480.jpg', 'images_364 (2).jpg', 'images_330 (2).jpg', 'images_348 (3).jpg', 'images_457.jpg', 'images_311.jpg', 'images_476 (3).jpg', 'images_524 (4).jpg', 'images_321.jpg', 'images_469.jpg', 'images_441 (3).jpg', 'images_310.jpg', 'images_337.jpg', 'images_351.jpg', 'images_294 (2).jpg', 'images_291 (2).jpg', 'images_252.jpg', 'images_355 (2).jpg', 'images_251.jpg', 'images_490 (2).jpg', 'images_231 (4).jpg', 'images_254.jpg', 'images_503.jpg', 'images_367.jpg', 'images_486 (2).jpg', 'images_510.jpg', 'images_430 (2).jpg', 'images_251 (3).jpg', 'images_375.jpg', 'images_374.jpg', 'images_458.jpg', 'images_533 (3).jpg', 'images_462.jpg', 'images_524 (2).jpg', 'images_402 (2).jpg', 'images_352 (2).jpg', 'images_264.jpg', 'images_414 (3).jpg', 'images_400.jpg', 'images_307.jpg', 'images_277 (3).jpg', 'images_398.jpg', 'images_437.jpg', 'images_405.jpg', 'images_303.jpg', 'images_320.jpg', 'images_407 (3).jpg', 'images_240.jpg', 'images_426 (2).jpg', 'images_431 (2).jpg', 'images_326.jpg', 'images_353 (2).jpg', 'images_413.jpg', 'images_276 (2).jpg', 'images_523 (2).jpg', 'images_409.jpg', 'images_322.jpg', 'images_535.jpg', 'images_428.jpg', 'images_328 (3).jpg', 'images_474.jpg', 'images_365.jpg', 'images_527.jpg', 'images_296 (2).jpg', 'images_453.jpg', 'images_346.jpg', 'images_354.jpg', 'images_447.jpg', 'images_407.jpg', 'images_348.jpg', 'images_251 (2).jpg', 'images_519 (2).jpg', 'images_253 (2).jpg', 'images_437 (3).jpg', 'images_453 (2).jpg', 'images_349.jpg', 'images_341 (3).jpg', 'images_408.jpg', 'images_316.jpg', 'images_352 (3).jpg', 'images_522 (2).jpg', 'images_537 (2).jpg', 'images_268 (3).jpg', 'images_525 (2).jpg', 'images_633.jpg', 'images_653 (2).jpg', 'images_544.jpg', 'images_610.jpg', 'images_597.jpg', 'images_575 (2).jpg', 'images_564.jpg', 'images_576.jpg', 'images_551 (2).jpg', 'images_640.jpg', 'images_564 (2).jpg', 'images_551 (4).jpg', 'images_654.jpg', 'images_649 (2).jpg', 'images_649.jpg', 'images_697.jpg', 'images_658 (2).jpg', 'images_662 (2).jpg', 'images_712 (2).jpg', 'images_554 (2).jpg', 'images_663 (2).jpg', 'images_615.jpg', 'images_651.jpg', 'images_631.jpg', 'images_678.jpg', 'images_549.jpg', 'images_801.jpg', 'images_637.jpg', 'images_644.jpg', 'images_624.jpg', 'images_667 (2).jpg', 'images_771.jpg', 'images_673 (3).jpg', 'images_606.jpg', 'images_569.jpg', 'images_585.jpg', 'images_717.jpg', 'images_584.jpg', 'images_560 (2).jpg', 'images_579 (2).jpg', 'images_638.jpg', 'images_549 (2).jpg', 'images_667.jpg', 'images_713.jpg', 'images_616.jpg', 'images_810.jpg', 'images_616 (2).jpg', 'images_721.jpg', 'images_679 (2).jpg', 'images_629.jpg', 'images_602.jpg', 'images_652.jpg', 'images_546 (2).jpg', 'images_649 (3).jpg', 'images_594 (3).jpg', 'images_589.jpg', 'images_681.jpg', 'images_672.jpg', 'images_776.jpg', 'images_645.jpg', 'images_642 (2).jpg', 'images_548 (2).jpg', 'images_797.jpg', 'images_590.jpg', 'images_605 (2).jpg', 'images_710.jpg', 'images_635 (2).jpg', 'images_646 (2).jpg', 'images_692 (2).jpg', 'images_621.jpg', 'images_725 (2).jpg', 'images_666.jpg', 'images_611 (2).jpg', 'images_630.jpg', 'images_684.jpg', 'images_695.jpg', 'images_726.jpg', 'images_581.jpg', 'images_573.jpg', 'images_598.jpg', 'images_650.jpg', 'images_675 (2).jpg', 'images_543 (3).jpg', 'images_690 (2).jpg', 'images_720 (2).jpg', 'images_665.jpg', 'images_575 (3).jpg', 'images_798.jpg', 'images_597 (2).jpg', 'images_578.jpg', 'images_642 (4).jpg', 'images_618 (3).jpg', 'images_560 (3).jpg', 'images_601 (2).jpg', 'images_700.jpg', 'images_731.jpg', 'images_712.jpg', 'images_575.jpg', 'images_748.jpg', 'images_796.jpg', 'images_596 (2).jpg', 'images_702.jpg', 'images_555 (2).jpg', 'images_607.jpg', 'images_678 (3).jpg', 'images_612.jpg', 'images_657.jpg', 'images_643 (2).jpg', 'images_562 (3).jpg', 'images_579 (3).jpg', 'images_769.jpg', 'images_565 (2).jpg', 'images_698.jpg', 'images_572 (2).jpg', 'images_765.jpg', 'images_681 (2).jpg', 'images_676 (2).jpg', 'images_595 (2).jpg', 'images_653.jpg', 'images_583 (2).jpg', 'images_547.jpg', 'images_577.jpg', 'images_605.jpg', 'images_711.jpg', 'images_671.jpg', 'images_544 (2).jpg', 'images_546.jpg', 'images_642.jpg', 'images_607 (2).jpg', 'images_678 (2).jpg', 'images_572.jpg', 'images_682.jpg', 'images_543.jpg', 'images_670.jpg', 'images_600.jpg', 'images_565.jpg', 'images_550 (2).jpg', 'images_702 (2).jpg', 'images_618 (2).jpg', 'images_610 (2).jpg', 'images_723.jpg', 'images_599 (2).jpg', 'images_559 (2).jpg', 'images_664 (2).jpg', 'images_631 (2).jpg', 'images_551.jpg', 'images_553.jpg', 'images_752.jpg', 'images_641.jpg', 'images_719.jpg', 'images_725.jpg', 'images_620.jpg', 'images_580.jpg', 'images_562 (2).jpg', 'images_554.jpg', 'images_557.jpg', 'images_680 (2).jpg', 'images_733.jpg', 'images_742.jpg', 'images_703.jpg', 'images_541.jpg', 'images_555.jpg', 'images_594 (2).jpg', 'images_703 (2).jpg', 'images_785.jpg', 'images_601.jpg', 'images_680.jpg', 'images_661 (2).jpg', 'images_624 (2).jpg', 'images_603.jpg', 'images_608.jpg', 'images_648 (2).jpg', 'images_570.jpg', 'images_567.jpg', 'images_593 (2).jpg', 'images_637 (2).jpg', 'images_548.jpg', 'images_708.jpg', 'images_582.jpg', 'images_726 (2).jpg', 'images_646 (3).jpg', 'images_586 (2).jpg', 'images_647.jpg', 'images_583.jpg', 'images_585 (2).jpg', 'images_596.jpg', 'images_551 (3).jpg', 'images_571.jpg', 'images_617.jpg', 'images_694.jpg', 'images_586.jpg', 'images_571 (2).jpg', 'images_600 (2).jpg', 'images_648.jpg', 'images_707.jpg', 'images_791.jpg', 'images_558.jpg', 'images_774.jpg', 'images_595.jpg', 'images_723 (2).jpg', 'images_568.jpg', 'images_562.jpg', 'images_782.jpg', 'images_699.jpg', 'images_662.jpg', 'images_713 (2).jpg', 'images_779.jpg', 'images_609.jpg', 'images_676.jpg', 'images_569 (2).jpg', 'images_558 (2).jpg', 'images_665 (2).jpg', 'images_561.jpg', 'images_642 (3).jpg', 'images_763.jpg', 'images_628.jpg', 'images_563.jpg', 'images_668.jpg', 'images_584 (2).jpg', 'images_628 (2).jpg', 'images_664 (3).jpg', 'images_644 (2).jpg', 'images_681 (3).jpg', 'images_658.jpg', 'images_599.jpg', 'images_674.jpg', 'images_665 (3).jpg', 'images_559.jpg', 'images_741.jpg', 'images_714.jpg', 'images_656.jpg', 'images_714 (2).jpg', 'images_564 (3).jpg', 'images_660.jpg', 'images_550 (3).jpg', 'images_619 (2).jpg', 'images_594.jpg', 'images_724.jpg', 'images_673.jpg', 'images_715.jpg', 'images_639.jpg', 'images_643.jpg', 'images_618.jpg', 'images_568 (3).jpg', 'images_606 (2).jpg', 'images_675.jpg', 'images_683 (2).jpg', 'images_593.jpg', 'images_692.jpg', 'images_550.jpg', 'images_679.jpg', 'images_665 (4).jpg', 'images_543 (2).jpg', 'images_640 (2).jpg', 'images_636.jpg', 'images_722.jpg', 'images_568 (2).jpg', 'images_634.jpg', 'images_611.jpg', 'images_549 (3).jpg', 'images_799.jpg', 'images_673 (2).jpg', 'images_718.jpg', 'images_693.jpg', 'images_617 (3).jpg', 'images_614.jpg', 'images_553 (2).jpg', 'images_632.jpg', 'images_639 (3).jpg', 'images_646.jpg', 'images_540.jpg', 'images_669 (2).jpg', 'images_803.jpg', 'images_659.jpg', 'images_612 (2).jpg', 'images_598 (2).jpg', 'images_732.jpg', 'images_617 (2).jpg', 'images_766.jpg', 'images_577 (2).jpg', 'images_579.jpg', 'images_692 (3).jpg', 'images_591.jpg', 'images_683.jpg', 'images_655.jpg', 'images_559 (3).jpg', 'images_758.jpg', 'images_720.jpg', 'images_664.jpg', 'images_777.jpg', 'images_588.jpg', 'images_627.jpg', 'images_600 (3).jpg', 'images_635.jpg', 'images_540 (2).jpg', 'images_560.jpg', 'images_663.jpg', 'images_636 (2).jpg', 'images_661.jpg', 'images_623.jpg', 'images_625.jpg', 'images_690.jpg', 'images_755.jpg', 'images_669.jpg', 'images_567 (2).jpg', 'images_639 (2).jpg', 'images_645 (2).jpg', 'images_566.jpg', 'images_619.jpg', 'images_686.jpg', 'images_812.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "Y0V6wyRpFHwZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics #intsalling yolo v8 a pretrained object detection model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObLicx1gROO1",
        "outputId": "b961ff51-b6c2-48bd-8f12-aa06feea4d66"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.38)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8m.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDub4u7kR78J",
        "outputId": "450af9fc-e512-4e8d-e62b-5e1da9e14ba3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 371MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0cEvaRnciuJ",
        "outputId": "acb86299-8518-4e5f-bf52-44dd6608b07f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.43)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (11.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.6)\n",
            "Requirement already satisfied: ultralytics>=8.2.34 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.3.38)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (75.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.12)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep-sort-realtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwNbMNDihNOU",
        "outputId": "665b3d72-caee-4636-cd42-a848103105d9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep-sort-realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (4.10.0.84)\n",
            "Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/8.4 MB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m141.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep-sort-realtime\n",
            "Successfully installed deep-sort-realtime-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(file_dir):\n",
        "  if filename.endswith(('.jpg', '.png', '.jpeg')):  # Check for image files\n",
        "    img_path = os.path.join(file_dir, filename)\n",
        "    results = model(img_path)  # Perform object detection\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uIuVTdNKjDba",
        "outputId": "5640733b-e5f1-4fd0-eb5a-bc70a44f8be7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_253.jpg: 384x640 4 cars, 829.1ms\n",
            "Speed: 3.7ms preprocess, 829.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_427.jpg: 448x640 6 persons, 11 cars, 3 motorcycles, 3 buss, 1 truck, 978.9ms\n",
            "Speed: 2.2ms preprocess, 978.9ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_503 (3).jpg: 256x640 10 cars, 5 buss, 1 truck, 551.8ms\n",
            "Speed: 1.5ms preprocess, 551.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_533.jpg: 448x640 1 person, 6 cars, 2 buss, 3 trucks, 4 traffic lights, 958.9ms\n",
            "Speed: 2.2ms preprocess, 958.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_297.jpg: 384x640 10 cars, 2 trucks, 1 cow, 1310.8ms\n",
            "Speed: 2.7ms preprocess, 1310.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_236 (2).jpg: 640x448 9 cars, 4 buss, 1 truck, 1644.8ms\n",
            "Speed: 3.2ms preprocess, 1644.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_278.jpg: 320x640 1 person, 1 bicycle, 14 cars, 688.6ms\n",
            "Speed: 1.7ms preprocess, 688.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_394.jpg: 384x640 1 person, 13 cars, 802.3ms\n",
            "Speed: 2.0ms preprocess, 802.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_448.jpg: 320x640 2 persons, 14 cars, 1 motorcycle, 672.0ms\n",
            "Speed: 1.7ms preprocess, 672.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_488 (2).jpg: 480x640 14 cars, 1 train, 3 trucks, 1777.6ms\n",
            "Speed: 3.5ms preprocess, 1777.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_324.jpg: 352x640 17 cars, 1 bus, 2 trucks, 969.4ms\n",
            "Speed: 2.5ms preprocess, 969.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_472 (2).jpg: 640x544 9 cars, 1 boat, 1182.4ms\n",
            "Speed: 2.7ms preprocess, 1182.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_308.jpg: 448x640 22 cars, 1 bus, 936.4ms\n",
            "Speed: 2.1ms preprocess, 936.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_280 (2).jpg: 384x640 2 persons, 7 cars, 1 motorcycle, 2 trucks, 805.5ms\n",
            "Speed: 2.1ms preprocess, 805.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_536 (2).jpg: 384x640 5 persons, 9 cars, 2 trucks, 823.4ms\n",
            "Speed: 1.9ms preprocess, 823.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_277.jpg: 384x640 10 cars, 7 buss, 5 trucks, 1 boat, 818.9ms\n",
            "Speed: 2.6ms preprocess, 818.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_301.jpg: 352x640 1 car, 4 trains, 2 trucks, 747.7ms\n",
            "Speed: 2.4ms preprocess, 747.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_539 (2).jpg: 544x640 1 person, 10 cars, 1147.3ms\n",
            "Speed: 3.5ms preprocess, 1147.3ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_537.jpg: 640x480 9 cars, 1027.6ms\n",
            "Speed: 3.0ms preprocess, 1027.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_380.jpg: 448x640 10 cars, 932.8ms\n",
            "Speed: 2.2ms preprocess, 932.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_368.jpg: 384x640 9 cars, 803.5ms\n",
            "Speed: 2.6ms preprocess, 803.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_503 (4).jpg: 480x640 (no detections), 1554.2ms\n",
            "Speed: 3.2ms preprocess, 1554.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_384.jpg: 640x448 1 person, 9 cars, 1 motorcycle, 1 handbag, 1835.4ms\n",
            "Speed: 3.1ms preprocess, 1835.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_437 (4).jpg: 448x640 12 cars, 7 trucks, 1500.2ms\n",
            "Speed: 3.7ms preprocess, 1500.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_367 (2).jpg: 448x640 6 cars, 3 buss, 1377.1ms\n",
            "Speed: 3.5ms preprocess, 1377.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_414 (4).jpg: 448x640 (no detections), 1212.9ms\n",
            "Speed: 4.9ms preprocess, 1212.9ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_438 (2).jpg: 416x640 (no detections), 1373.1ms\n",
            "Speed: 3.6ms preprocess, 1373.1ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_276.jpg: 384x640 11 cars, 1 bus, 4 trucks, 1332.1ms\n",
            "Speed: 2.9ms preprocess, 1332.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_514 (2).jpg: 448x640 1 person, 3 cars, 3 buss, 9 trucks, 1577.3ms\n",
            "Speed: 3.5ms preprocess, 1577.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_526 (2).jpg: 448x640 7 cars, 4 buss, 1 truck, 1282.4ms\n",
            "Speed: 3.0ms preprocess, 1282.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_328.jpg: 384x640 1 person, 2 cars, 1 bus, 5 trucks, 813.3ms\n",
            "Speed: 2.0ms preprocess, 813.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_267 (2).jpg: 480x640 2 cars, 1011.6ms\n",
            "Speed: 3.2ms preprocess, 1011.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_236.jpg: 448x640 7 persons, 7 cars, 2 motorcycles, 1 truck, 940.0ms\n",
            "Speed: 2.1ms preprocess, 940.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_391 (3).jpg: 416x640 1 wine glass, 1402.3ms\n",
            "Speed: 2.9ms preprocess, 1402.3ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_327.jpg: 640x576 4 persons, 7 cars, 2 motorcycles, 2 buss, 1941.3ms\n",
            "Speed: 3.9ms preprocess, 1941.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_461.jpg: 384x640 3 persons, 7 cars, 3 trucks, 1800.6ms\n",
            "Speed: 2.7ms preprocess, 1800.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_449 (2).jpg: 416x640 2 persons, 18 cars, 10 trucks, 1145.2ms\n",
            "Speed: 4.0ms preprocess, 1145.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_475 (2).jpg: 384x640 1 car, 799.6ms\n",
            "Speed: 2.1ms preprocess, 799.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_459 (3).jpg: 448x640 1 person, 4 cars, 942.0ms\n",
            "Speed: 3.2ms preprocess, 942.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_530.jpg: 352x640 4 persons, 8 cars, 1 motorcycle, 5 buss, 3 trucks, 752.3ms\n",
            "Speed: 2.6ms preprocess, 752.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_265 (2).jpg: 448x640 1 car, 947.3ms\n",
            "Speed: 2.4ms preprocess, 947.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_473.jpg: 448x640 1 person, 3 cars, 1 train, 939.1ms\n",
            "Speed: 3.0ms preprocess, 939.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_389.jpg: 384x640 3 persons, 7 cars, 3 buss, 3 trucks, 802.3ms\n",
            "Speed: 2.0ms preprocess, 802.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_491.jpg: 480x640 11 cars, 2 buss, 1019.8ms\n",
            "Speed: 3.4ms preprocess, 1019.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_365 (2).jpg: 448x640 1 person, 14 cars, 8 buss, 1 truck, 940.1ms\n",
            "Speed: 2.4ms preprocess, 940.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_329.jpg: 640x480 3 cars, 1017.9ms\n",
            "Speed: 2.5ms preprocess, 1017.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_337 (2).jpg: 352x640 9 cars, 1 bus, 1 truck, 1 traffic light, 733.3ms\n",
            "Speed: 2.7ms preprocess, 733.3ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_377 (2).jpg: 384x640 3 persons, 9 cars, 2 buss, 3 trucks, 1 traffic light, 992.4ms\n",
            "Speed: 4.0ms preprocess, 992.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_238.jpg: 480x640 15 cars, 2 buss, 5 trucks, 1619.2ms\n",
            "Speed: 3.3ms preprocess, 1619.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_502 (3).jpg: 352x640 2 persons, 5 cars, 1178.1ms\n",
            "Speed: 2.5ms preprocess, 1178.1ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_489 (2).jpg: 448x640 11 cars, 2 trucks, 1 traffic light, 1502.2ms\n",
            "Speed: 3.2ms preprocess, 1502.2ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_516 (2).jpg: 384x640 15 cars, 4 buss, 5 trucks, 1281.5ms\n",
            "Speed: 3.0ms preprocess, 1281.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_401 (2).jpg: 480x640 12 cars, 1059.3ms\n",
            "Speed: 2.3ms preprocess, 1059.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_517 (2).jpg: 448x640 4 cars, 972.0ms\n",
            "Speed: 2.6ms preprocess, 972.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_316 (2).jpg: 384x640 2 persons, 2 cars, 1 motorcycle, 9 buss, 804.7ms\n",
            "Speed: 2.0ms preprocess, 804.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_296.jpg: 384x640 8 persons, 10 cars, 2 motorcycles, 4 trucks, 800.0ms\n",
            "Speed: 2.7ms preprocess, 800.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_395.jpg: 384x640 2 persons, 7 cars, 3 trucks, 800.8ms\n",
            "Speed: 2.1ms preprocess, 800.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_293 (2).jpg: 384x640 5 cars, 1 motorcycle, 1 bus, 7 trucks, 802.6ms\n",
            "Speed: 2.0ms preprocess, 802.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_356.jpg: 480x640 5 persons, 5 cars, 5 buss, 2 trucks, 1013.8ms\n",
            "Speed: 3.0ms preprocess, 1013.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_430.jpg: 448x640 9 cars, 6 trucks, 939.7ms\n",
            "Speed: 2.3ms preprocess, 939.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_419.jpg: 352x640 6 persons, 10 cars, 5 buss, 5 trucks, 754.5ms\n",
            "Speed: 1.8ms preprocess, 754.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_355.jpg: 384x640 9 cars, 7 buss, 4 trucks, 794.2ms\n",
            "Speed: 2.1ms preprocess, 794.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_510 (2).jpg: 384x640 15 cars, 1 bus, 9 trucks, 833.9ms\n",
            "Speed: 2.0ms preprocess, 833.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_245.jpg: 448x640 6 cars, 1 truck, 1439.7ms\n",
            "Speed: 3.0ms preprocess, 1439.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_533 (2).jpg: 512x640 1 person, 13 cars, 1 bus, 2 trucks, 1743.9ms\n",
            "Speed: 3.6ms preprocess, 1743.9ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_463 (3).jpg: 640x480 (no detections), 1650.7ms\n",
            "Speed: 4.5ms preprocess, 1650.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_492.jpg: 480x640 3 persons, 9 cars, 1 bus, 6 trucks, 1021.0ms\n",
            "Speed: 3.5ms preprocess, 1021.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_273 (2).jpg: 448x640 2 persons, 9 cars, 1 motorcycle, 4 buss, 6 trucks, 941.2ms\n",
            "Speed: 3.1ms preprocess, 941.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_403 (2).jpg: 640x640 17 cars, 1 truck, 1340.5ms\n",
            "Speed: 3.0ms preprocess, 1340.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_294 (3).jpg: 416x640 6 cars, 857.8ms\n",
            "Speed: 2.2ms preprocess, 857.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_281.jpg: 384x640 (no detections), 801.3ms\n",
            "Speed: 2.4ms preprocess, 801.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_522.jpg: 448x640 3 persons, 7 cars, 3 buss, 2 trucks, 929.8ms\n",
            "Speed: 2.2ms preprocess, 929.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_241.jpg: 448x640 12 persons, 6 cars, 1 truck, 1 traffic light, 972.6ms\n",
            "Speed: 2.5ms preprocess, 972.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_412 (2).jpg: 384x640 8 cars, 2 trucks, 1 traffic light, 781.8ms\n",
            "Speed: 2.0ms preprocess, 781.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_494.jpg: 512x640 2 persons, 4 trucks, 1052.9ms\n",
            "Speed: 2.6ms preprocess, 1052.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_495.jpg: 384x640 9 cars, 6 trucks, 802.6ms\n",
            "Speed: 2.6ms preprocess, 802.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_515.jpg: 352x640 15 cars, 1043.3ms\n",
            "Speed: 2.4ms preprocess, 1043.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_534.jpg: 544x640 5 cars, 1780.7ms\n",
            "Speed: 3.6ms preprocess, 1780.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_306 (2).jpg: 480x640 16 cars, 1 bus, 2 trucks, 1608.7ms\n",
            "Speed: 6.4ms preprocess, 1608.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_278 (2).jpg: 480x640 4 cars, 2 trucks, 1193.8ms\n",
            "Speed: 3.6ms preprocess, 1193.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_487 (2).jpg: 352x640 3 cars, 4 buss, 1 truck, 727.6ms\n",
            "Speed: 2.7ms preprocess, 727.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_503 (2).jpg: 480x640 1 person, 19 cars, 1 bus, 1 truck, 1 handbag, 982.7ms\n",
            "Speed: 2.5ms preprocess, 982.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_336.jpg: 384x640 5 persons, 18 cars, 1 bus, 1 cow, 839.1ms\n",
            "Speed: 2.7ms preprocess, 839.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_372.jpg: 320x640 1 person, 1 bicycle, 14 cars, 693.9ms\n",
            "Speed: 1.6ms preprocess, 693.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_473 (2).jpg: 448x640 5 cars, 925.1ms\n",
            "Speed: 2.3ms preprocess, 925.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_518.jpg: 480x640 6 cars, 4 trucks, 988.8ms\n",
            "Speed: 2.4ms preprocess, 988.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_499 (2).jpg: 512x640 11 cars, 1054.6ms\n",
            "Speed: 2.6ms preprocess, 1054.6ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_443.jpg: 640x384 2 persons, 5 cars, 4 buss, 1 traffic light, 833.4ms\n",
            "Speed: 3.0ms preprocess, 833.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_492 (2).jpg: 352x640 5 cars, 9 trains, 734.8ms\n",
            "Speed: 1.8ms preprocess, 734.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_387 (3).jpg: 448x640 10 cars, 5 buss, 1 truck, 934.3ms\n",
            "Speed: 2.2ms preprocess, 934.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_389 (2).jpg: 512x640 3 cars, 4 trucks, 1510.5ms\n",
            "Speed: 2.7ms preprocess, 1510.5ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_300 (3).jpg: 416x640 (no detections), 1383.3ms\n",
            "Speed: 3.4ms preprocess, 1383.3ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_486.jpg: 352x640 5 cars, 2 trucks, 1 traffic light, 1199.6ms\n",
            "Speed: 2.8ms preprocess, 1199.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_362 (2).jpg: 480x640 15 cars, 2 trucks, 1282.4ms\n",
            "Speed: 3.2ms preprocess, 1282.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_370 (2).jpg: 480x640 2 cars, 10 buss, 1010.8ms\n",
            "Speed: 2.3ms preprocess, 1010.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_502 (2).jpg: 480x640 1 person, 20 cars, 1 motorcycle, 5 buss, 1013.4ms\n",
            "Speed: 2.3ms preprocess, 1013.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_391 (2).jpg: 480x640 1 person, 9 cars, 1012.3ms\n",
            "Speed: 3.1ms preprocess, 1012.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_252 (2).jpg: 448x640 19 cars, 3 buss, 4 trucks, 951.6ms\n",
            "Speed: 2.2ms preprocess, 951.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_350.jpg: 480x640 6 cars, 1 truck, 1005.8ms\n",
            "Speed: 2.4ms preprocess, 1005.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_246 (2).jpg: 384x640 7 cars, 817.6ms\n",
            "Speed: 2.8ms preprocess, 817.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_501.jpg: 384x640 18 cars, 1 bus, 3 trucks, 820.3ms\n",
            "Speed: 2.1ms preprocess, 820.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_395 (2).jpg: 384x640 21 cars, 3 buss, 5 trucks, 802.1ms\n",
            "Speed: 2.0ms preprocess, 802.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_303 (2).jpg: 544x640 8 cars, 1 bus, 5 trucks, 1134.6ms\n",
            "Speed: 2.6ms preprocess, 1134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_506 (3).jpg: 640x640 4 cars, 1754.2ms\n",
            "Speed: 3.0ms preprocess, 1754.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_256.jpg: 416x640 18 cars, 1 bus, 1375.3ms\n",
            "Speed: 2.9ms preprocess, 1375.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_431.jpg: 448x640 11 cars, 1538.4ms\n",
            "Speed: 3.0ms preprocess, 1538.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_398 (2).jpg: 608x640 1 car, 1511.8ms\n",
            "Speed: 3.9ms preprocess, 1511.8ms inference, 1.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_458 (2).jpg: 480x640 18 cars, 5 trucks, 1003.5ms\n",
            "Speed: 3.0ms preprocess, 1003.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_258.jpg: 480x640 4 persons, 7 cars, 4 buss, 1 truck, 1015.5ms\n",
            "Speed: 2.3ms preprocess, 1015.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_338.jpg: 416x640 1 bicycle, 11 cars, 1 truck, 920.9ms\n",
            "Speed: 2.3ms preprocess, 920.9ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_511.jpg: 192x640 6 cars, 6 trucks, 416.0ms\n",
            "Speed: 1.2ms preprocess, 416.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_514 (3).jpg: 480x640 12 cars, 1 bus, 2 trucks, 1017.5ms\n",
            "Speed: 3.0ms preprocess, 1017.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_344 (4).jpg: 448x640 8 cars, 1 truck, 1 traffic light, 947.0ms\n",
            "Speed: 2.3ms preprocess, 947.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_384 (3).jpg: 384x640 2 cars, 1 truck, 814.7ms\n",
            "Speed: 2.0ms preprocess, 814.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_399 (2).jpg: 384x640 11 cars, 1 bus, 4 trucks, 813.7ms\n",
            "Speed: 2.0ms preprocess, 813.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_271 (3).jpg: 416x640 (no detections), 862.9ms\n",
            "Speed: 2.1ms preprocess, 862.9ms inference, 0.7ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_461 (2).jpg: 448x640 10 cars, 1 bus, 4 trucks, 927.7ms\n",
            "Speed: 2.7ms preprocess, 927.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_323.jpg: 448x640 1 person, 2 cars, 1 bus, 2 trucks, 1431.1ms\n",
            "Speed: 3.4ms preprocess, 1431.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_433 (4).jpg: 512x640 22 cars, 1738.0ms\n",
            "Speed: 3.7ms preprocess, 1738.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_334 (2).jpg: 480x640 6 cars, 2 trucks, 1610.8ms\n",
            "Speed: 3.6ms preprocess, 1610.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_385 (2).jpg: 416x640 11 cars, 3 trucks, 857.8ms\n",
            "Speed: 2.0ms preprocess, 857.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_270.jpg: 448x640 14 cars, 944.2ms\n",
            "Speed: 2.6ms preprocess, 944.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_494 (2).jpg: 448x640 2 cars, 4 trucks, 1 boat, 943.0ms\n",
            "Speed: 2.3ms preprocess, 943.0ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_242.jpg: 384x640 8 persons, 12 cars, 2 buss, 1 truck, 804.1ms\n",
            "Speed: 2.0ms preprocess, 804.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_463.jpg: 384x640 1 person, 3 cars, 7 buss, 3 trucks, 786.8ms\n",
            "Speed: 1.9ms preprocess, 786.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_432.jpg: 448x640 1 person, 18 cars, 2 buss, 4 trucks, 935.4ms\n",
            "Speed: 2.7ms preprocess, 935.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_459 (2).jpg: 384x640 1 person, 6 cars, 5 buss, 1 truck, 797.8ms\n",
            "Speed: 3.6ms preprocess, 797.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_370.jpg: 384x640 12 cars, 3 trucks, 812.5ms\n",
            "Speed: 1.9ms preprocess, 812.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_261 (2).jpg: 288x640 1 person, 9 cars, 2 buss, 605.3ms\n",
            "Speed: 2.2ms preprocess, 605.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_346 (2).jpg: 416x640 9 cars, 1 bus, 1 truck, 874.3ms\n",
            "Speed: 2.8ms preprocess, 874.3ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_521 (2).jpg: 448x640 14 cars, 2 trucks, 930.6ms\n",
            "Speed: 2.3ms preprocess, 930.6ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_287.jpg: 448x640 6 cars, 5 buss, 2 trucks, 1300.1ms\n",
            "Speed: 2.8ms preprocess, 1300.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_389 (3).jpg: 416x640 6 persons, 4 cars, 1 truck, 3 suitcases, 1399.0ms\n",
            "Speed: 3.0ms preprocess, 1399.0ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_450.jpg: 384x640 2 persons, 7 cars, 1 bus, 4 trucks, 1297.6ms\n",
            "Speed: 2.5ms preprocess, 1297.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_357 (2).jpg: 352x640 1 person, 16 cars, 2 buss, 2 trucks, 1140.4ms\n",
            "Speed: 2.6ms preprocess, 1140.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_304.jpg: 480x640 8 cars, 2 buss, 7 trucks, 992.4ms\n",
            "Speed: 2.4ms preprocess, 992.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_388.jpg: 416x640 5 persons, 2 cars, 12 buss, 1 truck, 1 umbrella, 879.8ms\n",
            "Speed: 3.0ms preprocess, 879.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_423.jpg: 384x640 12 cars, 4 trucks, 803.5ms\n",
            "Speed: 2.7ms preprocess, 803.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_268 (2).jpg: 384x640 3 persons, 1 car, 5 buss, 6 trucks, 804.9ms\n",
            "Speed: 2.1ms preprocess, 804.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_471 (3).jpg: 384x640 14 cars, 3 trucks, 825.7ms\n",
            "Speed: 2.1ms preprocess, 825.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_274 (2).jpg: 384x640 3 cars, 1 tv, 806.7ms\n",
            "Speed: 2.9ms preprocess, 806.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_314.jpg: 480x640 15 cars, 1 bus, 3 trucks, 991.9ms\n",
            "Speed: 2.5ms preprocess, 991.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_418 (2).jpg: 416x640 11 cars, 1 bus, 869.9ms\n",
            "Speed: 2.4ms preprocess, 869.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_481 (3).jpg: 384x640 16 cars, 10 trucks, 812.0ms\n",
            "Speed: 2.7ms preprocess, 812.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_302 (2).jpg: 640x448 1 person, 3 cars, 949.5ms\n",
            "Speed: 2.4ms preprocess, 949.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_261.jpg: 640x640 3 persons, 3 cars, 8 buss, 2 trains, 1 truck, 1612.7ms\n",
            "Speed: 3.8ms preprocess, 1612.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_353 (3).jpg: 384x640 12 cars, 1 truck, 1283.1ms\n",
            "Speed: 2.7ms preprocess, 1283.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_231.jpg: 384x640 1 person, 8 cars, 1 bus, 1 truck, 1288.8ms\n",
            "Speed: 3.1ms preprocess, 1288.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_467.jpg: 384x640 10 cars, 1313.7ms\n",
            "Speed: 4.2ms preprocess, 1313.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_406 (4).jpg: 480x640 13 cars, 1 truck, 1003.3ms\n",
            "Speed: 3.0ms preprocess, 1003.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_263 (2).jpg: 416x640 13 cars, 3 trucks, 2 traffic lights, 874.7ms\n",
            "Speed: 2.2ms preprocess, 874.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_507.jpg: 384x640 1 person, 8 cars, 1 motorcycle, 1 traffic light, 801.2ms\n",
            "Speed: 2.0ms preprocess, 801.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_375 (3).jpg: 480x640 8 cars, 1 bus, 1008.2ms\n",
            "Speed: 2.4ms preprocess, 1008.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_374 (2).jpg: 448x640 11 cars, 3 trucks, 931.8ms\n",
            "Speed: 2.9ms preprocess, 931.8ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_418.jpg: 480x640 14 cars, 1018.9ms\n",
            "Speed: 2.3ms preprocess, 1018.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_328 (2).jpg: 480x640 10 cars, 2 trucks, 1000.8ms\n",
            "Speed: 3.2ms preprocess, 1000.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_294.jpg: 448x640 11 cars, 1 motorcycle, 2 buss, 2 trucks, 946.0ms\n",
            "Speed: 3.0ms preprocess, 946.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_424.jpg: 384x640 6 cars, 798.4ms\n",
            "Speed: 2.7ms preprocess, 798.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_277 (2).jpg: 480x640 15 cars, 1 truck, 1006.0ms\n",
            "Speed: 3.6ms preprocess, 1006.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_529.jpg: 384x640 15 cars, 1 bus, 1087.9ms\n",
            "Speed: 2.1ms preprocess, 1087.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_382.jpg: 384x640 1 person, 7 cars, 1 truck, 2 dogs, 1275.4ms\n",
            "Speed: 3.9ms preprocess, 1275.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_275.jpg: 416x640 7 persons, 4 cars, 12 buss, 1367.1ms\n",
            "Speed: 3.0ms preprocess, 1367.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_325.jpg: 448x640 14 cars, 1456.8ms\n",
            "Speed: 3.1ms preprocess, 1456.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_472.jpg: 384x640 14 cars, 9 trucks, 822.9ms\n",
            "Speed: 2.1ms preprocess, 822.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_517 (3).jpg: 480x640 14 cars, 1 bus, 2 trucks, 999.0ms\n",
            "Speed: 2.4ms preprocess, 999.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_527 (2).jpg: 448x640 10 cars, 1 bus, 939.6ms\n",
            "Speed: 3.0ms preprocess, 939.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_249 (2).jpg: 448x640 10 cars, 3 trucks, 941.4ms\n",
            "Speed: 2.8ms preprocess, 941.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_285.jpg: 416x640 1 person, 13 cars, 2 buss, 861.6ms\n",
            "Speed: 2.6ms preprocess, 861.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_400 (4).jpg: 448x640 10 cars, 953.3ms\n",
            "Speed: 2.3ms preprocess, 953.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_524.jpg: 480x640 7 cars, 3 trucks, 1018.7ms\n",
            "Speed: 2.3ms preprocess, 1018.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_292.jpg: 320x640 10 cars, 1 bus, 1 truck, 687.1ms\n",
            "Speed: 1.7ms preprocess, 687.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_265.jpg: 384x640 9 cars, 1 truck, 798.0ms\n",
            "Speed: 1.9ms preprocess, 798.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_434.jpg: 544x640 4 persons, 6 cars, 2 motorcycles, 3 trucks, 1127.3ms\n",
            "Speed: 2.5ms preprocess, 1127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_392 (2).jpg: 448x640 2 persons, 6 cars, 1206.5ms\n",
            "Speed: 3.5ms preprocess, 1206.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_235.jpg: 448x640 19 cars, 3 buss, 4 trucks, 1493.3ms\n",
            "Speed: 3.1ms preprocess, 1493.3ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_508 (3).jpg: 320x640 1 car, 2 buss, 4 trains, 4 trucks, 1074.3ms\n",
            "Speed: 2.3ms preprocess, 1074.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_450 (2).jpg: 448x640 14 cars, 1 bus, 3 trucks, 1488.5ms\n",
            "Speed: 3.0ms preprocess, 1488.5ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_360 (2).jpg: 448x640 12 cars, 4 trucks, 952.8ms\n",
            "Speed: 3.1ms preprocess, 952.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_433 (2).jpg: 448x640 21 cars, 2 trucks, 936.9ms\n",
            "Speed: 2.3ms preprocess, 936.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_280 (3).jpg: 384x640 5 persons, 4 cars, 817.0ms\n",
            "Speed: 2.7ms preprocess, 817.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_261 (3).jpg: 448x640 6 cars, 932.7ms\n",
            "Speed: 2.4ms preprocess, 932.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_490.jpg: 448x640 5 cars, 2 buss, 1 truck, 948.4ms\n",
            "Speed: 2.3ms preprocess, 948.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_347.jpg: 480x640 7 cars, 1 truck, 1023.3ms\n",
            "Speed: 3.3ms preprocess, 1023.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_338 (2).jpg: 384x640 (no detections), 815.6ms\n",
            "Speed: 2.6ms preprocess, 815.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_504 (2).jpg: 480x640 11 cars, 991.9ms\n",
            "Speed: 3.3ms preprocess, 991.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_442.jpg: 416x640 2 persons, 18 cars, 879.9ms\n",
            "Speed: 3.2ms preprocess, 879.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_263.jpg: 384x640 13 cars, 2 buss, 790.9ms\n",
            "Speed: 2.5ms preprocess, 790.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_531.jpg: 384x640 12 cars, 1 truck, 2 traffic lights, 916.9ms\n",
            "Speed: 2.4ms preprocess, 916.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_295.jpg: 480x640 4 persons, 13 cars, 1 bus, 1 truck, 1586.7ms\n",
            "Speed: 3.3ms preprocess, 1586.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_378.jpg: 320x640 6 cars, 1139.7ms\n",
            "Speed: 2.5ms preprocess, 1139.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_449.jpg: 320x640 11 cars, 1 truck, 1088.4ms\n",
            "Speed: 2.4ms preprocess, 1088.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_441.jpg: 448x640 10 cars, 4 buss, 3 trucks, 1202.6ms\n",
            "Speed: 2.9ms preprocess, 1202.6ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_307 (2).jpg: 448x640 2 persons, 6 cars, 3 buss, 3 trucks, 1692.2ms\n",
            "Speed: 2.2ms preprocess, 1692.2ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_526.jpg: 352x640 1 person, 2 cars, 6 buss, 1 train, 5 trucks, 1380.1ms\n",
            "Speed: 2.7ms preprocess, 1380.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_270 (2).jpg: 640x608 5 cars, 7 buss, 3 trucks, 1410.6ms\n",
            "Speed: 4.0ms preprocess, 1410.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_429 (2).jpg: 352x640 2 cars, 1 traffic light, 774.3ms\n",
            "Speed: 2.3ms preprocess, 774.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_303 (4).jpg: 448x640 8 cars, 1 bus, 7 trucks, 955.4ms\n",
            "Speed: 2.3ms preprocess, 955.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_386 (3).jpg: 384x640 9 cars, 4 trucks, 899.1ms\n",
            "Speed: 2.9ms preprocess, 899.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_406.jpg: 384x640 10 cars, 1 bus, 2 trucks, 808.0ms\n",
            "Speed: 2.6ms preprocess, 808.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_414 (2).jpg: 544x640 9 persons, 2 cars, 2 motorcycles, 1 backpack, 1136.2ms\n",
            "Speed: 3.0ms preprocess, 1136.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_487.jpg: 320x640 1 person, 1 car, 2 buss, 1 truck, 904.4ms\n",
            "Speed: 1.7ms preprocess, 904.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_286 (3).jpg: 384x640 10 cars, 2 buss, 1 truck, 1278.6ms\n",
            "Speed: 2.8ms preprocess, 1278.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_242 (2).jpg: 448x640 1 person, 11 cars, 1 bus, 1 truck, 1564.0ms\n",
            "Speed: 3.0ms preprocess, 1564.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_388 (2).jpg: 480x640 8 cars, 1 truck, 1654.5ms\n",
            "Speed: 3.3ms preprocess, 1654.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_536.jpg: 448x640 8 cars, 3 trucks, 997.0ms\n",
            "Speed: 2.8ms preprocess, 997.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_497 (2).jpg: 384x640 6 cars, 1 truck, 908.0ms\n",
            "Speed: 2.6ms preprocess, 908.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_283 (2).jpg: 384x640 3 cars, 9 buss, 1 truck, 807.4ms\n",
            "Speed: 3.3ms preprocess, 807.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_269.jpg: 352x640 17 cars, 806.3ms\n",
            "Speed: 2.4ms preprocess, 806.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_233 (2).jpg: 384x640 19 cars, 4 buss, 4 trucks, 799.7ms\n",
            "Speed: 2.0ms preprocess, 799.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_498 (2).jpg: 512x640 5 cars, 1 bus, 1076.1ms\n",
            "Speed: 3.3ms preprocess, 1076.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_428 (2).jpg: 384x640 12 cars, 5 trucks, 816.0ms\n",
            "Speed: 2.0ms preprocess, 816.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_336 (3).jpg: 416x640 11 cars, 1 bus, 862.0ms\n",
            "Speed: 2.1ms preprocess, 862.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_481 (2).jpg: 640x480 10 cars, 4 trucks, 1012.5ms\n",
            "Speed: 2.3ms preprocess, 1012.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_247.jpg: 416x640 11 cars, 1 bus, 872.4ms\n",
            "Speed: 2.1ms preprocess, 872.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_286.jpg: 384x640 7 persons, 7 cars, 3 buss, 1 truck, 1066.4ms\n",
            "Speed: 2.2ms preprocess, 1066.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_397.jpg: 384x640 15 cars, 4 trucks, 1489.8ms\n",
            "Speed: 2.8ms preprocess, 1489.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_532.jpg: 384x640 20 cars, 1451.8ms\n",
            "Speed: 3.6ms preprocess, 1451.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_512.jpg: 480x640 3 cars, 1 bus, 5 trains, 4 trucks, 1796.1ms\n",
            "Speed: 3.4ms preprocess, 1796.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_271.jpg: 512x640 16 cars, 4 buss, 3 trucks, 2040.8ms\n",
            "Speed: 3.5ms preprocess, 2040.8ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_288 (3).jpg: 480x640 (no detections), 1485.9ms\n",
            "Speed: 5.0ms preprocess, 1485.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_403.jpg: 384x640 11 persons, 6 motorcycles, 2 umbrellas, 814.6ms\n",
            "Speed: 2.1ms preprocess, 814.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_440 (2).jpg: 480x640 24 cars, 3 buss, 1038.5ms\n",
            "Speed: 3.2ms preprocess, 1038.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_359 (2).jpg: 640x608 8 persons, 13 cars, 4 buss, 2 trucks, 1299.3ms\n",
            "Speed: 3.4ms preprocess, 1299.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_484.jpg: 416x640 8 cars, 2 buss, 863.2ms\n",
            "Speed: 4.4ms preprocess, 863.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_508 (2).jpg: 384x640 14 cars, 1 bus, 798.8ms\n",
            "Speed: 3.7ms preprocess, 798.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_514.jpg: 640x480 8 cars, 2 buss, 4 trucks, 1002.5ms\n",
            "Speed: 3.3ms preprocess, 1002.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_420.jpg: 448x640 7 cars, 10 buss, 934.0ms\n",
            "Speed: 3.1ms preprocess, 934.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_387.jpg: 384x640 4 persons, 14 cars, 1 bus, 827.4ms\n",
            "Speed: 2.0ms preprocess, 827.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_445.jpg: 480x640 15 cars, 1018.7ms\n",
            "Speed: 3.0ms preprocess, 1018.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_416 (2).jpg: 384x640 4 persons, 5 cars, 1 truck, 1282.4ms\n",
            "Speed: 2.9ms preprocess, 1282.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_375 (2).jpg: 448x640 12 cars, 5 trucks, 1512.7ms\n",
            "Speed: 3.1ms preprocess, 1512.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_411.jpg: 480x640 4 persons, 11 cars, 1 bus, 1 truck, 1661.3ms\n",
            "Speed: 3.4ms preprocess, 1661.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_360.jpg: 384x640 7 cars, 7 buss, 1 truck, 1 traffic light, 845.9ms\n",
            "Speed: 2.8ms preprocess, 845.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_318.jpg: 384x640 5 cars, 1 bus, 1 truck, 800.7ms\n",
            "Speed: 2.0ms preprocess, 800.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_246.jpg: 448x640 11 cars, 1 truck, 936.5ms\n",
            "Speed: 2.9ms preprocess, 936.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_288 (2).jpg: 384x640 1 person, 5 cars, 805.2ms\n",
            "Speed: 2.0ms preprocess, 805.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_523.jpg: 352x640 10 cars, 2 traffic lights, 745.5ms\n",
            "Speed: 2.5ms preprocess, 745.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_282 (2).jpg: 512x640 12 cars, 1 bus, 1 truck, 1066.1ms\n",
            "Speed: 3.4ms preprocess, 1066.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_451.jpg: 352x640 1 person, 4 cars, 3 buss, 6 trains, 2 trucks, 739.0ms\n",
            "Speed: 1.9ms preprocess, 739.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_471 (2).jpg: 384x640 3 persons, 14 cars, 1 motorcycle, 1 bus, 4 trucks, 804.9ms\n",
            "Speed: 2.0ms preprocess, 804.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_237.jpg: 384x640 10 cars, 2 buss, 2 trucks, 810.4ms\n",
            "Speed: 2.1ms preprocess, 810.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_272.jpg: 384x640 7 cars, 1 bus, 1 truck, 801.5ms\n",
            "Speed: 2.5ms preprocess, 801.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_269 (2).jpg: 480x640 7 cars, 2 buss, 5 trucks, 1 traffic light, 1007.9ms\n",
            "Speed: 3.7ms preprocess, 1007.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_345.jpg: 448x640 12 cars, 1 bus, 1181.1ms\n",
            "Speed: 2.9ms preprocess, 1181.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_314 (2).jpg: 384x640 11 cars, 2 buss, 4 trucks, 3 traffic lights, 1298.2ms\n",
            "Speed: 2.7ms preprocess, 1298.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_361.jpg: 640x640 10 cars, 1 bus, 2178.8ms\n",
            "Speed: 4.3ms preprocess, 2178.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_381.jpg: 416x640 6 cars, 2 trucks, 1028.7ms\n",
            "Speed: 2.9ms preprocess, 1028.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_273.jpg: 384x640 11 cars, 801.5ms\n",
            "Speed: 2.0ms preprocess, 801.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_282.jpg: 448x640 9 cars, 2 buss, 2 traffic lights, 929.8ms\n",
            "Speed: 4.0ms preprocess, 929.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_520 (2).jpg: 384x640 12 cars, 3 buss, 4 trucks, 815.3ms\n",
            "Speed: 3.1ms preprocess, 815.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_270 (3).jpg: 448x640 13 cars, 978.0ms\n",
            "Speed: 3.2ms preprocess, 978.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_342.jpg: 480x640 3 persons, 4 cars, 9 buss, 1016.5ms\n",
            "Speed: 2.4ms preprocess, 1016.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_248 (2).jpg: 448x640 16 cars, 1 bus, 5 trucks, 1130.9ms\n",
            "Speed: 2.8ms preprocess, 1130.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_491 (2).jpg: 384x640 6 cars, 2 buss, 1 train, 7 trucks, 1004.0ms\n",
            "Speed: 3.3ms preprocess, 1004.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_505.jpg: 352x640 4 persons, 7 cars, 1 truck, 895.7ms\n",
            "Speed: 1.8ms preprocess, 895.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_455.jpg: 448x640 6 cars, 1 bus, 2 trucks, 935.1ms\n",
            "Speed: 2.9ms preprocess, 935.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_300 (2).jpg: 480x640 1 person, 14 cars, 2 buss, 1184.7ms\n",
            "Speed: 2.4ms preprocess, 1184.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_366 (2).jpg: 384x640 1 person, 10 cars, 2 buss, 1 truck, 1275.2ms\n",
            "Speed: 2.7ms preprocess, 1275.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_538 (2).jpg: 480x640 1 person, 5 cars, 1600.1ms\n",
            "Speed: 3.3ms preprocess, 1600.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_279.jpg: 384x640 3 cars, 3 buss, 1 train, 1343.2ms\n",
            "Speed: 2.9ms preprocess, 1343.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_358.jpg: 448x640 7 persons, 3 cars, 2 trucks, 943.5ms\n",
            "Speed: 3.1ms preprocess, 943.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_248.jpg: 448x640 2 persons, 6 cars, 5 buss, 955.3ms\n",
            "Speed: 2.2ms preprocess, 955.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_351 (2).jpg: 640x416 9 cars, 919.4ms\n",
            "Speed: 2.3ms preprocess, 919.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_327 (2).jpg: 448x640 9 cars, 1 truck, 937.4ms\n",
            "Speed: 2.2ms preprocess, 937.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_244.jpg: 384x640 15 cars, 1 bus, 3 trucks, 796.9ms\n",
            "Speed: 2.6ms preprocess, 796.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_431 (3).jpg: 480x640 14 cars, 995.6ms\n",
            "Speed: 2.5ms preprocess, 995.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_341.jpg: 224x640 15 cars, 8 trucks, 494.7ms\n",
            "Speed: 1.8ms preprocess, 494.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_236 (3).jpg: 480x640 14 cars, 1 bus, 1017.5ms\n",
            "Speed: 2.3ms preprocess, 1017.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_399.jpg: 384x640 10 cars, 2 trucks, 823.7ms\n",
            "Speed: 2.0ms preprocess, 823.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_373 (2).jpg: 320x640 5 persons, 14 cars, 2 buss, 5 trucks, 669.0ms\n",
            "Speed: 1.8ms preprocess, 669.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_457 (2).jpg: 384x640 16 cars, 3 trucks, 801.2ms\n",
            "Speed: 2.0ms preprocess, 801.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_260.jpg: 448x640 1 car, 2 traffic lights, 1272.8ms\n",
            "Speed: 2.7ms preprocess, 1272.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_384 (2).jpg: 384x640 13 cars, 2 boats, 1328.5ms\n",
            "Speed: 2.8ms preprocess, 1328.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_480 (2).jpg: 640x448 7 cars, 3 trucks, 1527.3ms\n",
            "Speed: 3.1ms preprocess, 1527.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_360 (4).jpg: 288x640 8 cars, 7 buss, 979.0ms\n",
            "Speed: 2.1ms preprocess, 979.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_412.jpg: 416x640 13 cars, 3 trucks, 2 traffic lights, 865.7ms\n",
            "Speed: 2.1ms preprocess, 865.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_302.jpg: 640x448 3 cars, 948.9ms\n",
            "Speed: 3.0ms preprocess, 948.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_259.jpg: 448x640 7 cars, 1 bus, 1 truck, 942.8ms\n",
            "Speed: 3.0ms preprocess, 942.8ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_406 (3).jpg: 384x640 4 persons, 8 cars, 1 truck, 809.8ms\n",
            "Speed: 2.8ms preprocess, 809.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_380 (2).jpg: 256x640 15 cars, 1 bus, 1 traffic light, 577.4ms\n",
            "Speed: 1.7ms preprocess, 577.4ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_358 (2).jpg: 448x640 5 cars, 1 bus, 1 truck, 965.9ms\n",
            "Speed: 2.8ms preprocess, 965.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_250.jpg: 352x640 10 cars, 4 trucks, 761.0ms\n",
            "Speed: 1.8ms preprocess, 761.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_429.jpg: 640x640 1 person, 11 cars, 1 truck, 1 traffic light, 1332.6ms\n",
            "Speed: 4.2ms preprocess, 1332.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_411 (3).jpg: 416x640 3 persons, 9 cars, 3 buss, 877.9ms\n",
            "Speed: 3.0ms preprocess, 877.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_470.jpg: 448x640 2 persons, 7 cars, 934.7ms\n",
            "Speed: 2.9ms preprocess, 934.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_353.jpg: 480x640 7 persons, 10 cars, 3 buss, 1 truck, 1214.4ms\n",
            "Speed: 2.4ms preprocess, 1214.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_332.jpg: 416x640 (no detections), 1377.1ms\n",
            "Speed: 2.9ms preprocess, 1377.1ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_414.jpg: 448x640 12 persons, 1 car, 1 truck, 1518.4ms\n",
            "Speed: 3.2ms preprocess, 1518.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_383.jpg: 448x640 1 person, 7 cars, 1406.0ms\n",
            "Speed: 3.1ms preprocess, 1406.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_441 (2).jpg: 384x640 11 cars, 1 truck, 810.1ms\n",
            "Speed: 2.3ms preprocess, 810.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_483.jpg: 384x640 7 cars, 1 truck, 1 traffic light, 808.7ms\n",
            "Speed: 2.0ms preprocess, 808.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_433 (3).jpg: 480x640 1 person, 14 cars, 1 motorcycle, 2 buss, 5 trucks, 1002.4ms\n",
            "Speed: 2.6ms preprocess, 1002.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_232.jpg: 384x640 3 persons, 5 cars, 1 bus, 816.7ms\n",
            "Speed: 2.1ms preprocess, 816.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_259 (2).jpg: 480x640 1 person, 8 cars, 997.9ms\n",
            "Speed: 3.3ms preprocess, 997.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_393.jpg: 448x640 1 person, 9 cars, 943.7ms\n",
            "Speed: 3.0ms preprocess, 943.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_343.jpg: 384x640 1 person, 3 buss, 1 truck, 814.3ms\n",
            "Speed: 2.7ms preprocess, 814.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_364.jpg: 416x640 1 person, 8 cars, 1 motorcycle, 866.1ms\n",
            "Speed: 3.0ms preprocess, 866.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_465 (2).jpg: 480x640 6 persons, 4 cars, 5 buss, 2 trucks, 1001.4ms\n",
            "Speed: 2.4ms preprocess, 1001.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_257 (2).jpg: 384x640 11 cars, 1 truck, 1 traffic light, 815.3ms\n",
            "Speed: 3.3ms preprocess, 815.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_344 (2).jpg: 480x640 1 person, 7 cars, 1184.0ms\n",
            "Speed: 2.4ms preprocess, 1184.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_317 (2).jpg: 640x480 10 cars, 1 truck, 1640.5ms\n",
            "Speed: 3.2ms preprocess, 1640.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_341 (2).jpg: 384x640 5 cars, 1280.7ms\n",
            "Speed: 5.3ms preprocess, 1280.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_393 (2).jpg: 416x640 7 cars, 4 buss, 3 trucks, 1323.2ms\n",
            "Speed: 2.8ms preprocess, 1323.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_520.jpg: 384x640 14 cars, 4 trucks, 807.8ms\n",
            "Speed: 3.2ms preprocess, 807.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_440.jpg: 384x640 6 persons, 13 cars, 5 trucks, 1 umbrella, 815.2ms\n",
            "Speed: 2.1ms preprocess, 815.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_376.jpg: 384x640 2 persons, 19 cars, 4 buss, 1 truck, 813.6ms\n",
            "Speed: 2.1ms preprocess, 813.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_482.jpg: 448x640 5 cars, 919.0ms\n",
            "Speed: 2.6ms preprocess, 919.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_439.jpg: 448x640 1 train, 935.5ms\n",
            "Speed: 2.2ms preprocess, 935.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_280.jpg: 416x640 4 persons, 14 cars, 1 motorcycle, 2 buss, 2 trucks, 922.1ms\n",
            "Speed: 2.2ms preprocess, 922.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_416.jpg: 448x640 16 cars, 5 trucks, 936.2ms\n",
            "Speed: 2.1ms preprocess, 936.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_370 (3).jpg: 416x640 6 cars, 1 bus, 1 truck, 872.8ms\n",
            "Speed: 2.2ms preprocess, 872.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_371.jpg: 384x640 9 cars, 4 trucks, 807.0ms\n",
            "Speed: 2.0ms preprocess, 807.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_506 (2).jpg: 448x640 2 persons, 1 car, 17 buss, 2 trucks, 935.5ms\n",
            "Speed: 2.7ms preprocess, 935.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_271 (2).jpg: 384x640 18 cars, 4 trucks, 819.0ms\n",
            "Speed: 2.5ms preprocess, 819.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_409 (2).jpg: 640x448 2 persons, 10 cars, 1 motorcycle, 2 buss, 2 trucks, 1492.9ms\n",
            "Speed: 3.0ms preprocess, 1492.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_506.jpg: 320x640 1 person, 7 cars, 1 truck, 1105.1ms\n",
            "Speed: 2.5ms preprocess, 1105.1ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_283.jpg: 384x640 17 cars, 2 buss, 1 truck, 1286.1ms\n",
            "Speed: 2.8ms preprocess, 1286.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_421.jpg: 448x640 7 persons, 7 cars, 3 motorcycles, 4 buss, 1 truck, 1261.9ms\n",
            "Speed: 3.1ms preprocess, 1261.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_477 (2).jpg: 384x640 9 cars, 2 buss, 1 truck, 810.9ms\n",
            "Speed: 2.3ms preprocess, 810.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_492 (3).jpg: 448x640 13 cars, 2 buss, 6 trucks, 940.4ms\n",
            "Speed: 2.9ms preprocess, 940.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_425 (2).jpg: 320x640 2 persons, 18 cars, 1 bus, 691.0ms\n",
            "Speed: 1.7ms preprocess, 691.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_394 (2).jpg: 384x640 (no detections), 807.0ms\n",
            "Speed: 2.1ms preprocess, 807.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_249.jpg: 384x640 5 cars, 3 buss, 6 trucks, 815.9ms\n",
            "Speed: 2.1ms preprocess, 815.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_485.jpg: 384x640 13 cars, 1 truck, 792.1ms\n",
            "Speed: 2.0ms preprocess, 792.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_489.jpg: 480x640 4 persons, 5 cars, 6 buss, 1 truck, 999.2ms\n",
            "Speed: 2.3ms preprocess, 999.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_232 (3).jpg: 384x640 4 cars, 1 truck, 812.1ms\n",
            "Speed: 2.0ms preprocess, 812.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_438.jpg: 384x640 16 cars, 10 trucks, 807.6ms\n",
            "Speed: 3.2ms preprocess, 807.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_232 (2).jpg: 480x640 6 persons, 6 cars, 7 buss, 1 train, 996.3ms\n",
            "Speed: 2.3ms preprocess, 996.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_524 (3).jpg: 352x640 6 cars, 1 bus, 2 trucks, 763.7ms\n",
            "Speed: 2.4ms preprocess, 763.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_489 (3).jpg: 480x640 1 person, 15 cars, 7 buss, 1 truck, 1539.0ms\n",
            "Speed: 3.1ms preprocess, 1539.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_405 (2).jpg: 640x640 8 cars, 2167.0ms\n",
            "Speed: 5.3ms preprocess, 2167.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_385.jpg: 384x640 21 cars, 1 truck, 1 stop sign, 1215.5ms\n",
            "Speed: 2.7ms preprocess, 1215.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_243.jpg: 448x640 6 persons, 5 cars, 10 buss, 2 trucks, 941.8ms\n",
            "Speed: 2.2ms preprocess, 941.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_433.jpg: 384x640 14 cars, 1 bus, 816.7ms\n",
            "Speed: 2.1ms preprocess, 816.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_256 (2).jpg: 384x640 3 cars, 1 bus, 7 trucks, 1 bed, 809.3ms\n",
            "Speed: 2.0ms preprocess, 809.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_493.jpg: 480x640 7 cars, 1 bus, 5 trucks, 998.5ms\n",
            "Speed: 2.3ms preprocess, 998.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_489 (4).jpg: 384x640 16 cars, 3 trucks, 817.5ms\n",
            "Speed: 2.6ms preprocess, 817.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_498.jpg: 384x640 1 person, 9 cars, 3 buss, 816.6ms\n",
            "Speed: 2.3ms preprocess, 816.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_504.jpg: 320x640 1 person, 12 cars, 3 trucks, 716.9ms\n",
            "Speed: 2.0ms preprocess, 716.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_244 (2).jpg: 384x640 9 persons, 6 cars, 1 motorcycle, 1 bus, 806.5ms\n",
            "Speed: 2.6ms preprocess, 806.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_476 (2).jpg: 416x640 3 persons, 7 cars, 1 motorcycle, 4 buss, 2 trucks, 867.3ms\n",
            "Speed: 5.4ms preprocess, 867.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_454.jpg: 448x640 2 persons, 13 cars, 2 motorcycles, 1 truck, 939.6ms\n",
            "Speed: 2.4ms preprocess, 939.6ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_402.jpg: 448x640 20 cars, 4 buss, 954.1ms\n",
            "Speed: 2.1ms preprocess, 954.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_306.jpg: 352x640 2 persons, 15 cars, 1 motorcycle, 1136.1ms\n",
            "Speed: 2.4ms preprocess, 1136.1ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_525.jpg: 480x640 3 persons, 11 cars, 1 bus, 1604.8ms\n",
            "Speed: 3.7ms preprocess, 1604.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_402 (3).jpg: 416x640 1 train, 1 truck, 1470.6ms\n",
            "Speed: 4.9ms preprocess, 1470.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_456 (2).jpg: 448x640 1 person, 4 cars, 1 motorcycle, 1 traffic light, 1120.2ms\n",
            "Speed: 3.4ms preprocess, 1120.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_442 (2).jpg: 576x640 10 cars, 1220.0ms\n",
            "Speed: 3.7ms preprocess, 1220.0ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_387 (2).jpg: 448x640 12 cars, 1 truck, 934.4ms\n",
            "Speed: 2.9ms preprocess, 934.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_300.jpg: 480x640 16 cars, 1005.4ms\n",
            "Speed: 3.1ms preprocess, 1005.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_510 (3).jpg: 448x640 1 bus, 3 trains, 5 trucks, 943.5ms\n",
            "Speed: 2.5ms preprocess, 943.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_483 (2).jpg: 448x640 14 cars, 1 bus, 3 trucks, 949.3ms\n",
            "Speed: 2.8ms preprocess, 949.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_399 (3).jpg: 448x640 1 bus, 947.2ms\n",
            "Speed: 2.9ms preprocess, 947.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_479 (2).jpg: 480x640 2 persons, 9 cars, 1 bus, 1 truck, 1008.0ms\n",
            "Speed: 3.8ms preprocess, 1008.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_378 (2).jpg: 416x640 2 persons, 4 cars, 2 buss, 870.5ms\n",
            "Speed: 2.2ms preprocess, 870.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_330.jpg: 352x640 1 person, 7 cars, 5 buss, 1 truck, 733.0ms\n",
            "Speed: 2.5ms preprocess, 733.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_386.jpg: 384x640 1 car, 3 trains, 5 trucks, 950.1ms\n",
            "Speed: 2.0ms preprocess, 950.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_331.jpg: 384x640 10 cars, 2 buss, 1 truck, 1283.5ms\n",
            "Speed: 2.9ms preprocess, 1283.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_317.jpg: 416x640 7 persons, 12 cars, 1 bus, 1370.0ms\n",
            "Speed: 2.8ms preprocess, 1370.0ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_340.jpg: 480x640 1 person, 13 cars, 5 buss, 1 truck, 1625.0ms\n",
            "Speed: 9.3ms preprocess, 1625.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_465.jpg: 384x640 12 cars, 2 buss, 810.8ms\n",
            "Speed: 3.6ms preprocess, 810.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_425.jpg: 384x640 2 persons, 8 cars, 3 buss, 2 trucks, 803.8ms\n",
            "Speed: 2.8ms preprocess, 803.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_471.jpg: 384x640 3 cars, 1 bus, 812.7ms\n",
            "Speed: 2.6ms preprocess, 812.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_286 (2).jpg: 480x640 6 cars, 2 trucks, 1008.2ms\n",
            "Speed: 2.4ms preprocess, 1008.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_461 (3).jpg: 448x640 2 persons, 16 cars, 2 motorcycles, 5 trucks, 940.7ms\n",
            "Speed: 2.6ms preprocess, 940.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_509.jpg: 416x640 14 cars, 1 truck, 864.9ms\n",
            "Speed: 3.0ms preprocess, 864.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_390 (2).jpg: 352x640 9 cars, 736.8ms\n",
            "Speed: 1.8ms preprocess, 736.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_406 (2).jpg: 384x640 3 persons, 11 cars, 846.5ms\n",
            "Speed: 2.1ms preprocess, 846.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_479.jpg: 448x640 16 cars, 2 buss, 1 truck, 938.9ms\n",
            "Speed: 3.7ms preprocess, 938.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_499.jpg: 448x640 18 cars, 1 bus, 1 truck, 1 traffic light, 955.1ms\n",
            "Speed: 3.1ms preprocess, 955.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_253 (3).jpg: 448x640 14 cars, 2 buss, 944.8ms\n",
            "Speed: 2.3ms preprocess, 944.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_462 (2).jpg: 352x640 14 cars, 1 bus, 4 trucks, 1 fire hydrant, 1137.7ms\n",
            "Speed: 1.9ms preprocess, 1137.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_462 (3).jpg: 384x640 1 person, 15 cars, 2 buss, 1271.8ms\n",
            "Speed: 3.2ms preprocess, 1271.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_258 (2).jpg: 384x640 6 persons, 2 cars, 3 buss, 1 train, 4 trucks, 1300.7ms\n",
            "Speed: 2.7ms preprocess, 1300.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_349 (2).jpg: 384x640 2 persons, 16 cars, 1 bus, 2 trucks, 1187.5ms\n",
            "Speed: 2.7ms preprocess, 1187.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_293.jpg: 448x640 14 cars, 11 buss, 1 truck, 933.7ms\n",
            "Speed: 2.2ms preprocess, 933.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_231 (2).jpg: 448x640 5 cars, 1 truck, 1 traffic light, 946.5ms\n",
            "Speed: 2.3ms preprocess, 946.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_536 (3).jpg: 640x480 4 cars, 1017.2ms\n",
            "Speed: 2.6ms preprocess, 1017.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_460 (2).jpg: 416x640 10 cars, 1 bus, 5 trucks, 1 traffic light, 849.8ms\n",
            "Speed: 3.4ms preprocess, 849.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_522 (3).jpg: 384x640 9 cars, 1 bus, 803.6ms\n",
            "Speed: 2.7ms preprocess, 803.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_522 (4).jpg: 448x640 1 person, 7 cars, 6 buss, 950.3ms\n",
            "Speed: 3.5ms preprocess, 950.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_517.jpg: 352x640 10 cars, 2 buss, 8 trucks, 754.5ms\n",
            "Speed: 4.3ms preprocess, 754.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_463 (2).jpg: 384x640 7 cars, 6 buss, 812.1ms\n",
            "Speed: 2.8ms preprocess, 812.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_502.jpg: 480x640 2 persons, 17 cars, 3 buss, 5 trucks, 1001.6ms\n",
            "Speed: 2.3ms preprocess, 1001.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_239.jpg: 544x640 15 cars, 1 bus, 2 trucks, 1132.7ms\n",
            "Speed: 3.6ms preprocess, 1132.7ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_303 (5).jpg: 448x640 5 cars, 1 bus, 3 trucks, 1256.5ms\n",
            "Speed: 2.6ms preprocess, 1256.5ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_419 (2).jpg: 448x640 1 car, 1 bus, 1511.8ms\n",
            "Speed: 3.1ms preprocess, 1511.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_262 (2).jpg: 448x640 6 cars, 2 trucks, 1 traffic light, 1533.7ms\n",
            "Speed: 7.4ms preprocess, 1533.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_360 (3).jpg: 448x640 1 person, 13 cars, 2 trucks, 1263.6ms\n",
            "Speed: 3.1ms preprocess, 1263.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_511 (3).jpg: 384x640 4 cars, 1 traffic light, 814.7ms\n",
            "Speed: 2.1ms preprocess, 814.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_400 (3).jpg: 544x640 2 cars, 1135.3ms\n",
            "Speed: 4.0ms preprocess, 1135.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_516.jpg: 480x640 1 person, 13 cars, 1 motorcycle, 3 trucks, 1015.7ms\n",
            "Speed: 2.4ms preprocess, 1015.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_410.jpg: 448x640 12 cars, 1 bus, 943.1ms\n",
            "Speed: 2.7ms preprocess, 943.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_468 (2).jpg: 448x640 1 person, 14 cars, 1 motorcycle, 2 buss, 4 trucks, 945.4ms\n",
            "Speed: 3.0ms preprocess, 945.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_475.jpg: 416x640 2 persons, 4 cars, 4 trucks, 874.2ms\n",
            "Speed: 2.3ms preprocess, 874.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_377.jpg: 448x640 6 cars, 2 buss, 2 trucks, 971.4ms\n",
            "Speed: 3.1ms preprocess, 971.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_446.jpg: 480x640 9 cars, 1 truck, 1016.7ms\n",
            "Speed: 3.3ms preprocess, 1016.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_400 (2).jpg: 480x640 4 persons, 5 cars, 2 buss, 2 trucks, 1013.1ms\n",
            "Speed: 2.4ms preprocess, 1013.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_404 (2).jpg: 288x640 (no detections), 604.2ms\n",
            "Speed: 1.6ms preprocess, 604.2ms inference, 0.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_417.jpg: 448x640 1 person, 12 cars, 3 trucks, 1525.6ms\n",
            "Speed: 5.6ms preprocess, 1525.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_407 (2).jpg: 416x640 10 cars, 3 trucks, 2 potted plants, 1393.5ms\n",
            "Speed: 2.8ms preprocess, 1393.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_267.jpg: 416x640 2 cars, 1430.1ms\n",
            "Speed: 4.0ms preprocess, 1430.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_235 (2).jpg: 448x640 2 persons, 10 cars, 1 bus, 1044.0ms\n",
            "Speed: 3.2ms preprocess, 1044.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_336 (2).jpg: 352x640 2 persons, 7 cars, 2 buss, 1 truck, 738.0ms\n",
            "Speed: 2.8ms preprocess, 738.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_448 (3).jpg: 480x640 1 person, 4 cars, 4 buss, 1038.3ms\n",
            "Speed: 3.3ms preprocess, 1038.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_305 (2).jpg: 576x640 7 persons, 8 cars, 1 bus, 1837.7ms\n",
            "Speed: 2.8ms preprocess, 1837.7ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_447 (2).jpg: 384x640 1 bus, 1302.1ms\n",
            "Speed: 2.7ms preprocess, 1302.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_381 (2).jpg: 416x640 5 cars, 1430.7ms\n",
            "Speed: 3.1ms preprocess, 1430.7ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_459.jpg: 384x640 6 persons, 5 buss, 1 truck, 908.8ms\n",
            "Speed: 2.8ms preprocess, 908.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_497.jpg: 384x640 4 persons, 8 cars, 5 motorcycles, 1 bus, 3 trucks, 800.9ms\n",
            "Speed: 2.8ms preprocess, 800.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_404.jpg: 640x640 5 persons, 11 cars, 4 motorcycles, 1 bus, 3 trucks, 1549.7ms\n",
            "Speed: 4.1ms preprocess, 1549.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_391.jpg: 448x640 21 cars, 1 truck, 1484.8ms\n",
            "Speed: 3.7ms preprocess, 1484.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_450 (3).jpg: 448x640 10 cars, 3 buss, 3 trucks, 1512.9ms\n",
            "Speed: 3.1ms preprocess, 1512.9ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_409 (3).jpg: 448x640 13 cars, 2 buss, 1343.4ms\n",
            "Speed: 3.2ms preprocess, 1343.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_538.jpg: 416x640 5 persons, 4 cars, 2 buss, 2 trains, 4 trucks, 866.5ms\n",
            "Speed: 2.9ms preprocess, 866.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_295 (2).jpg: 640x448 10 cars, 2 buss, 2 trucks, 953.4ms\n",
            "Speed: 3.1ms preprocess, 953.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_344.jpg: 640x448 9 cars, 2 buss, 4 trucks, 972.1ms\n",
            "Speed: 3.6ms preprocess, 972.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_457 (3).jpg: 384x640 4 cars, 7 buss, 1 truck, 820.8ms\n",
            "Speed: 1.9ms preprocess, 820.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_268.jpg: 384x640 3 persons, 10 cars, 5 trucks, 792.5ms\n",
            "Speed: 2.0ms preprocess, 792.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_456.jpg: 448x640 3 cars, 12 buss, 936.3ms\n",
            "Speed: 3.1ms preprocess, 936.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_344 (3).jpg: 480x640 6 cars, 7 buss, 1 truck, 1003.8ms\n",
            "Speed: 2.9ms preprocess, 1003.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_250 (2).jpg: 640x448 (no detections), 972.5ms\n",
            "Speed: 2.7ms preprocess, 972.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_352.jpg: 384x640 9 cars, 1 bus, 7 trucks, 836.2ms\n",
            "Speed: 2.8ms preprocess, 836.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_427 (2).jpg: 384x640 15 cars, 3 buss, 811.4ms\n",
            "Speed: 2.9ms preprocess, 811.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_339.jpg: 416x640 12 cars, 4 trucks, 1085.2ms\n",
            "Speed: 2.2ms preprocess, 1085.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_532 (2).jpg: 416x640 12 cars, 1 truck, 1382.5ms\n",
            "Speed: 2.9ms preprocess, 1382.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_303 (3).jpg: 384x640 7 cars, 2 buss, 1294.7ms\n",
            "Speed: 4.7ms preprocess, 1294.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_290.jpg: 448x640 11 cars, 1 bus, 1491.2ms\n",
            "Speed: 3.3ms preprocess, 1491.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_363.jpg: 448x640 1 person, 11 cars, 1 bus, 952.5ms\n",
            "Speed: 2.8ms preprocess, 952.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_369.jpg: 512x640 9 cars, 1075.6ms\n",
            "Speed: 3.6ms preprocess, 1075.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_359.jpg: 512x640 22 cars, 1 truck, 1073.5ms\n",
            "Speed: 3.6ms preprocess, 1073.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_357.jpg: 416x640 6 cars, 3 buss, 865.0ms\n",
            "Speed: 2.9ms preprocess, 865.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_481.jpg: 448x640 14 cars, 2 buss, 1 truck, 936.1ms\n",
            "Speed: 3.0ms preprocess, 936.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_511 (2).jpg: 448x640 9 persons, 4 cars, 8 buss, 6 trucks, 946.1ms\n",
            "Speed: 2.7ms preprocess, 946.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_323 (2).jpg: 640x448 4 cars, 1 train, 969.6ms\n",
            "Speed: 2.4ms preprocess, 969.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_348 (2).jpg: 448x640 8 persons, 9 cars, 3 trucks, 952.0ms\n",
            "Speed: 2.7ms preprocess, 952.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_477.jpg: 384x640 3 cars, 1 bottle, 2 cell phones, 792.3ms\n",
            "Speed: 2.0ms preprocess, 792.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_447 (3).jpg: 384x640 16 cars, 1 bus, 799.8ms\n",
            "Speed: 2.7ms preprocess, 799.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_436.jpg: 384x640 (no detections), 1095.3ms\n",
            "Speed: 3.0ms preprocess, 1095.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_437 (2).jpg: 384x640 1 car, 12 buss, 1 truck, 4 umbrellas, 1262.5ms\n",
            "Speed: 2.7ms preprocess, 1262.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_386 (2).jpg: 320x640 6 cars, 1 truck, 1078.7ms\n",
            "Speed: 2.8ms preprocess, 1078.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_390.jpg: 384x640 9 cars, 1 bus, 3 trucks, 1335.9ms\n",
            "Speed: 2.7ms preprocess, 1335.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_392.jpg: 448x640 2 persons, 9 cars, 1 motorcycle, 2 trucks, 1002.8ms\n",
            "Speed: 3.2ms preprocess, 1002.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_347 (2).jpg: 448x640 14 cars, 3 trucks, 3 traffic lights, 938.1ms\n",
            "Speed: 3.1ms preprocess, 938.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_529 (2).jpg: 448x640 12 cars, 3 buss, 1 truck, 942.9ms\n",
            "Speed: 4.8ms preprocess, 942.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_495 (2).jpg: 448x640 (no detections), 946.9ms\n",
            "Speed: 3.3ms preprocess, 946.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_537 (4).jpg: 640x640 1 person, 1 car, 14 buss, 1340.1ms\n",
            "Speed: 3.5ms preprocess, 1340.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_335.jpg: 448x640 7 cars, 1 truck, 948.6ms\n",
            "Speed: 3.2ms preprocess, 948.6ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_376 (2).jpg: 640x640 10 cars, 1 bus, 1321.4ms\n",
            "Speed: 4.1ms preprocess, 1321.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_247 (2).jpg: 384x640 4 persons, 4 cars, 799.4ms\n",
            "Speed: 2.8ms preprocess, 799.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_460.jpg: 320x640 1 person, 4 cars, 3 buss, 5 trucks, 723.0ms\n",
            "Speed: 2.5ms preprocess, 723.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_373.jpg: 448x640 1 person, 6 cars, 6 buss, 2 trucks, 929.2ms\n",
            "Speed: 5.1ms preprocess, 929.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_291.jpg: 448x640 11 cars, 3 trucks, 1507.6ms\n",
            "Speed: 4.0ms preprocess, 1507.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_537 (3).jpg: 448x640 1 person, 7 cars, 9 buss, 2 trucks, 1505.6ms\n",
            "Speed: 3.3ms preprocess, 1505.6ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_415.jpg: 480x640 2 persons, 1 car, 1 bus, 1 truck, 1644.8ms\n",
            "Speed: 3.3ms preprocess, 1644.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_417 (2).jpg: 352x640 1 person, 7 cars, 2 trucks, 2 traffic lights, 751.3ms\n",
            "Speed: 2.5ms preprocess, 751.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_422.jpg: 384x640 16 cars, 1 truck, 794.8ms\n",
            "Speed: 4.1ms preprocess, 794.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_478 (2).jpg: 544x640 4 persons, 6 cars, 2 motorcycles, 3 trucks, 1146.4ms\n",
            "Speed: 2.7ms preprocess, 1146.4ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_461 (4).jpg: 448x640 10 cars, 4 trucks, 3 traffic lights, 941.3ms\n",
            "Speed: 3.0ms preprocess, 941.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_504 (3).jpg: 352x640 14 cars, 1 truck, 744.5ms\n",
            "Speed: 2.5ms preprocess, 744.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_393 (3).jpg: 480x640 8 cars, 1 truck, 1003.0ms\n",
            "Speed: 3.1ms preprocess, 1003.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_315.jpg: 416x640 9 cars, 861.2ms\n",
            "Speed: 2.9ms preprocess, 861.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_362.jpg: 384x640 2 persons, 11 cars, 2 motorcycles, 1 bus, 2 trucks, 810.5ms\n",
            "Speed: 2.7ms preprocess, 810.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_334.jpg: 384x640 6 cars, 3 buss, 808.2ms\n",
            "Speed: 2.7ms preprocess, 808.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_314 (3).jpg: 448x640 16 cars, 1 truck, 939.3ms\n",
            "Speed: 3.2ms preprocess, 939.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_411 (2).jpg: 384x640 12 cars, 1 truck, 1 stop sign, 794.6ms\n",
            "Speed: 2.9ms preprocess, 794.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_426.jpg: 480x640 16 cars, 2 trucks, 1493.5ms\n",
            "Speed: 3.3ms preprocess, 1493.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_518 (2).jpg: 480x640 6 cars, 1 bus, 1 truck, 1619.8ms\n",
            "Speed: 3.4ms preprocess, 1619.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_373 (3).jpg: 384x640 13 cars, 1 bus, 4 trucks, 1 traffic light, 1300.7ms\n",
            "Speed: 2.7ms preprocess, 1300.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_284 (2).jpg: 384x640 4 cars, 1 truck, 1017.6ms\n",
            "Speed: 3.0ms preprocess, 1017.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_345 (2).jpg: 320x640 6 cars, 1 truck, 670.1ms\n",
            "Speed: 2.5ms preprocess, 670.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_287 (2).jpg: 544x640 7 cars, 1 bus, 1 train, 1132.0ms\n",
            "Speed: 3.8ms preprocess, 1132.0ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_519.jpg: 448x640 8 cars, 3 trucks, 935.0ms\n",
            "Speed: 3.4ms preprocess, 935.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_284.jpg: 416x640 13 cars, 1 bus, 2 trucks, 883.2ms\n",
            "Speed: 4.3ms preprocess, 883.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_410 (2).jpg: 384x640 6 cars, 3 traffic lights, 813.0ms\n",
            "Speed: 2.0ms preprocess, 813.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_513.jpg: 480x640 13 cars, 1 bus, 2 trucks, 1001.4ms\n",
            "Speed: 4.0ms preprocess, 1001.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_262.jpg: 384x640 22 cars, 6 trucks, 805.7ms\n",
            "Speed: 2.4ms preprocess, 805.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_274.jpg: 448x640 15 cars, 3 trucks, 959.2ms\n",
            "Speed: 3.1ms preprocess, 959.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_488.jpg: 416x640 8 cars, 1 bus, 1 truck, 871.2ms\n",
            "Speed: 2.4ms preprocess, 871.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_521.jpg: 384x640 21 cars, 2 trucks, 820.3ms\n",
            "Speed: 2.6ms preprocess, 820.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_401.jpg: 448x640 4 persons, 1 motorcycle, 2 buss, 6 trucks, 1250.8ms\n",
            "Speed: 4.3ms preprocess, 1250.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_310 (2).jpg: 448x640 12 cars, 1 bus, 4 trucks, 1505.3ms\n",
            "Speed: 3.4ms preprocess, 1505.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_266.jpg: 416x640 8 cars, 1 bus, 3 trucks, 1411.3ms\n",
            "Speed: 4.0ms preprocess, 1411.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_288.jpg: 416x640 12 cars, 1 bus, 2 trucks, 1228.3ms\n",
            "Speed: 3.3ms preprocess, 1228.3ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_476.jpg: 448x640 1 person, 18 cars, 3 buss, 3 trucks, 923.5ms\n",
            "Speed: 3.3ms preprocess, 923.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_340 (2).jpg: 384x640 8 cars, 1 bus, 800.2ms\n",
            "Speed: 3.9ms preprocess, 800.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_367 (3).jpg: 448x640 16 cars, 4 trucks, 956.4ms\n",
            "Speed: 4.6ms preprocess, 956.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_417 (3).jpg: 448x640 10 cars, 4 buss, 1 truck, 942.9ms\n",
            "Speed: 2.5ms preprocess, 942.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_468.jpg: 288x640 5 persons, 9 cars, 7 buss, 1 train, 1 truck, 2 traffic lights, 625.5ms\n",
            "Speed: 2.3ms preprocess, 625.5ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_484 (2).jpg: 320x640 8 cars, 675.8ms\n",
            "Speed: 2.3ms preprocess, 675.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_231 (3).jpg: 384x640 10 cars, 6 trucks, 796.9ms\n",
            "Speed: 2.8ms preprocess, 796.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_366.jpg: 352x640 1 person, 1 car, 3 buss, 3 trucks, 745.6ms\n",
            "Speed: 2.4ms preprocess, 745.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_321 (2).jpg: 384x640 10 cars, 2 buss, 4 trucks, 804.2ms\n",
            "Speed: 2.8ms preprocess, 804.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_379.jpg: 448x640 1 car, 937.9ms\n",
            "Speed: 3.0ms preprocess, 937.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_422 (2).jpg: 320x640 1 person, 2 cars, 1 bus, 3 trucks, 677.8ms\n",
            "Speed: 2.5ms preprocess, 677.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_371 (2).jpg: 448x640 14 cars, 1 bus, 1 truck, 1187.2ms\n",
            "Speed: 3.0ms preprocess, 1187.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_508.jpg: 480x640 5 cars, 4 buss, 1 truck, 1608.0ms\n",
            "Speed: 3.3ms preprocess, 1608.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_279 (2).jpg: 384x640 13 cars, 1 truck, 1283.3ms\n",
            "Speed: 2.8ms preprocess, 1283.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_539.jpg: 448x640 10 cars, 11 trucks, 1385.9ms\n",
            "Speed: 4.2ms preprocess, 1385.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_257.jpg: 384x640 15 cars, 799.5ms\n",
            "Speed: 3.3ms preprocess, 799.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_496.jpg: 448x640 1 person, 5 cars, 6 buss, 2 trucks, 937.5ms\n",
            "Speed: 3.0ms preprocess, 937.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_305.jpg: 512x640 2 persons, 10 cars, 3 trucks, 1096.8ms\n",
            "Speed: 3.5ms preprocess, 1096.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_448 (2).jpg: 352x640 1 bus, 4 trucks, 755.0ms\n",
            "Speed: 3.0ms preprocess, 755.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_478.jpg: 416x640 12 cars, 1 bus, 873.0ms\n",
            "Speed: 3.1ms preprocess, 873.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_326 (2).jpg: 384x640 4 persons, 1 bicycle, 10 cars, 2 buss, 1 truck, 811.7ms\n",
            "Speed: 2.0ms preprocess, 811.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_480.jpg: 384x640 13 cars, 3 buss, 799.0ms\n",
            "Speed: 2.3ms preprocess, 799.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_364 (2).jpg: 640x640 10 cars, 3 trucks, 1 boat, 1331.5ms\n",
            "Speed: 3.6ms preprocess, 1331.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_330 (2).jpg: 384x640 1 person, 15 cars, 3 buss, 2 trucks, 810.3ms\n",
            "Speed: 1.9ms preprocess, 810.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_348 (3).jpg: 448x640 3 cars, 1 truck, 946.7ms\n",
            "Speed: 2.6ms preprocess, 946.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_457.jpg: 384x640 1 car, 7 buss, 1 train, 1124.7ms\n",
            "Speed: 2.4ms preprocess, 1124.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_311.jpg: 448x640 18 cars, 2 buss, 2 trucks, 1503.7ms\n",
            "Speed: 3.2ms preprocess, 1503.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_476 (3).jpg: 384x640 (no detections), 1299.9ms\n",
            "Speed: 2.8ms preprocess, 1299.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_524 (4).jpg: 640x640 2 persons, 3 cars, 4 buss, 2 trucks, 1738.6ms\n",
            "Speed: 3.9ms preprocess, 1738.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_321.jpg: 416x640 2 trains, 862.5ms\n",
            "Speed: 2.3ms preprocess, 862.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_469.jpg: 384x640 10 persons, 5 cars, 4 buss, 804.4ms\n",
            "Speed: 2.7ms preprocess, 804.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_441 (3).jpg: 352x640 5 cars, 739.5ms\n",
            "Speed: 2.6ms preprocess, 739.5ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_310.jpg: 384x640 4 persons, 16 cars, 2 trucks, 805.3ms\n",
            "Speed: 3.0ms preprocess, 805.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_337.jpg: 448x640 12 cars, 1 bus, 7 trucks, 933.9ms\n",
            "Speed: 2.6ms preprocess, 933.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_351.jpg: 448x640 7 cars, 1 bus, 3 trucks, 946.8ms\n",
            "Speed: 2.3ms preprocess, 946.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_294 (2).jpg: 448x640 16 cars, 2 trucks, 948.3ms\n",
            "Speed: 3.1ms preprocess, 948.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_291 (2).jpg: 384x640 11 cars, 813.1ms\n",
            "Speed: 2.7ms preprocess, 813.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_252.jpg: 416x640 12 cars, 1 bus, 864.5ms\n",
            "Speed: 2.9ms preprocess, 864.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_355 (2).jpg: 384x640 8 cars, 1 bus, 809.6ms\n",
            "Speed: 2.7ms preprocess, 809.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_251.jpg: 384x640 9 persons, 1 car, 8 buss, 933.5ms\n",
            "Speed: 6.1ms preprocess, 933.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_490 (2).jpg: 384x640 8 cars, 1 bus, 1 truck, 1286.5ms\n",
            "Speed: 2.8ms preprocess, 1286.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_231 (4).jpg: 480x640 2 cars, 2 trucks, 1632.1ms\n",
            "Speed: 3.4ms preprocess, 1632.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_254.jpg: 480x640 4 cars, 3 buss, 1538.4ms\n",
            "Speed: 3.3ms preprocess, 1538.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_503.jpg: 416x640 5 persons, 5 cars, 1 bus, 6 trucks, 2 umbrellas, 859.1ms\n",
            "Speed: 2.2ms preprocess, 859.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_367.jpg: 384x640 3 persons, 14 cars, 1 motorcycle, 1 bus, 4 trucks, 805.0ms\n",
            "Speed: 2.7ms preprocess, 805.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_486 (2).jpg: 352x640 5 cars, 3 buss, 3 trucks, 744.3ms\n",
            "Speed: 1.9ms preprocess, 744.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_510.jpg: 384x640 13 cars, 7 traffic lights, 806.3ms\n",
            "Speed: 2.5ms preprocess, 806.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_430 (2).jpg: 640x608 6 cars, 2 buss, 1 truck, 1258.0ms\n",
            "Speed: 4.4ms preprocess, 1258.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_251 (3).jpg: 448x640 9 cars, 950.8ms\n",
            "Speed: 2.6ms preprocess, 950.8ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_375.jpg: 288x640 7 persons, 5 cars, 2 suitcases, 618.6ms\n",
            "Speed: 1.7ms preprocess, 618.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_374.jpg: 448x640 13 persons, 1 bicycle, 5 cars, 4 buss, 1 train, 3 trucks, 944.3ms\n",
            "Speed: 3.0ms preprocess, 944.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_458.jpg: 384x640 20 cars, 2 trucks, 799.3ms\n",
            "Speed: 2.9ms preprocess, 799.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_533 (3).jpg: 384x640 19 cars, 798.4ms\n",
            "Speed: 2.1ms preprocess, 798.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_462.jpg: 480x640 7 cars, 2 motorcycles, 1 bus, 2 trucks, 1013.4ms\n",
            "Speed: 3.7ms preprocess, 1013.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_524 (2).jpg: 640x352 9 cars, 1 truck, 1266.1ms\n",
            "Speed: 2.6ms preprocess, 1266.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_402 (2).jpg: 480x640 1 tie, 1615.4ms\n",
            "Speed: 3.3ms preprocess, 1615.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_352 (2).jpg: 384x640 8 persons, 14 cars, 1342.4ms\n",
            "Speed: 2.9ms preprocess, 1342.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_264.jpg: 384x640 7 cars, 1 bus, 3 trucks, 983.4ms\n",
            "Speed: 2.6ms preprocess, 983.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_414 (3).jpg: 384x640 11 cars, 1 truck, 1 traffic light, 798.6ms\n",
            "Speed: 3.1ms preprocess, 798.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_400.jpg: 640x512 1 person, 3 cars, 1 traffic light, 1093.4ms\n",
            "Speed: 3.6ms preprocess, 1093.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_307.jpg: 448x640 11 cars, 1 truck, 935.4ms\n",
            "Speed: 3.2ms preprocess, 935.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_277 (3).jpg: 384x640 2 cars, 1 truck, 815.7ms\n",
            "Speed: 4.6ms preprocess, 815.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_398.jpg: 416x640 8 persons, 1 bus, 873.6ms\n",
            "Speed: 2.2ms preprocess, 873.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_437.jpg: 480x640 7 persons, 1 car, 2 buss, 4 trucks, 986.1ms\n",
            "Speed: 2.4ms preprocess, 986.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_405.jpg: 384x640 10 cars, 4 buss, 1 truck, 794.6ms\n",
            "Speed: 2.7ms preprocess, 794.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_303.jpg: 352x640 4 persons, 10 cars, 4 buss, 5 trucks, 749.3ms\n",
            "Speed: 2.7ms preprocess, 749.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_320.jpg: 448x640 9 cars, 945.1ms\n",
            "Speed: 2.3ms preprocess, 945.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_407 (3).jpg: 384x640 4 persons, 2 cars, 1 bus, 3 trains, 2 trucks, 813.2ms\n",
            "Speed: 2.7ms preprocess, 813.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_240.jpg: 480x640 5 cars, 1 bus, 1 truck, 1302.1ms\n",
            "Speed: 2.5ms preprocess, 1302.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_426 (2).jpg: 384x640 11 cars, 3 trucks, 1292.0ms\n",
            "Speed: 2.8ms preprocess, 1292.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_431 (2).jpg: 416x640 2 persons, 18 cars, 10 trucks, 1460.1ms\n",
            "Speed: 3.0ms preprocess, 1460.1ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_326.jpg: 480x640 14 cars, 1 bus, 4 trucks, 1400.5ms\n",
            "Speed: 3.9ms preprocess, 1400.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_353 (2).jpg: 384x640 12 cars, 1 bus, 3 trucks, 3 traffic lights, 809.1ms\n",
            "Speed: 2.4ms preprocess, 809.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_413.jpg: 448x640 5 persons, 16 cars, 2 buss, 1 traffic light, 939.9ms\n",
            "Speed: 3.3ms preprocess, 939.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_276 (2).jpg: 480x640 1 person, 12 cars, 1 motorcycle, 2 trucks, 1030.7ms\n",
            "Speed: 3.3ms preprocess, 1030.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_523 (2).jpg: 448x640 1 person, 3 cars, 3 buss, 9 trucks, 945.3ms\n",
            "Speed: 2.7ms preprocess, 945.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_409.jpg: 416x640 12 cars, 6 trucks, 865.8ms\n",
            "Speed: 3.1ms preprocess, 865.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_322.jpg: 480x640 1 car, 2 trains, 1021.1ms\n",
            "Speed: 3.2ms preprocess, 1021.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_535.jpg: 448x640 2 persons, 6 cars, 4 buss, 2 trucks, 950.5ms\n",
            "Speed: 2.4ms preprocess, 950.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_428.jpg: 448x640 7 cars, 10 buss, 948.2ms\n",
            "Speed: 3.2ms preprocess, 948.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_328 (3).jpg: 448x640 3 cars, 2 trucks, 935.7ms\n",
            "Speed: 3.3ms preprocess, 935.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_474.jpg: 352x640 3 persons, 9 cars, 4 trucks, 755.9ms\n",
            "Speed: 2.5ms preprocess, 755.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_365.jpg: 640x640 3 cars, 2057.0ms\n",
            "Speed: 4.1ms preprocess, 2057.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_527.jpg: 352x640 1 person, 5 cars, 3 buss, 1 truck, 1 traffic light, 1175.2ms\n",
            "Speed: 2.6ms preprocess, 1175.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_296 (2).jpg: 480x640 8 cars, 1664.0ms\n",
            "Speed: 5.3ms preprocess, 1664.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_453.jpg: 384x640 6 persons, 3 buss, 1 train, 4 trucks, 1 boat, 852.8ms\n",
            "Speed: 2.7ms preprocess, 852.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_346.jpg: 640x544 1 cell phone, 1160.8ms\n",
            "Speed: 3.5ms preprocess, 1160.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_354.jpg: 384x640 1 person, 14 cars, 1 bus, 806.1ms\n",
            "Speed: 3.2ms preprocess, 806.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_447.jpg: 448x640 8 persons, 11 cars, 2 trucks, 926.9ms\n",
            "Speed: 2.9ms preprocess, 926.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_407.jpg: 448x640 6 cars, 926.5ms\n",
            "Speed: 3.5ms preprocess, 926.5ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_348.jpg: 480x640 13 cars, 5 trucks, 982.5ms\n",
            "Speed: 3.6ms preprocess, 982.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_251 (2).jpg: 480x640 1 person, 11 cars, 1 truck, 977.7ms\n",
            "Speed: 3.4ms preprocess, 977.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_519 (2).jpg: 448x640 16 cars, 1 motorcycle, 2 trucks, 933.9ms\n",
            "Speed: 3.2ms preprocess, 933.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_253 (2).jpg: 480x640 7 cars, 2 buss, 5 trucks, 1 traffic light, 982.8ms\n",
            "Speed: 5.0ms preprocess, 982.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_437 (3).jpg: 384x640 16 cars, 3 trucks, 809.6ms\n",
            "Speed: 2.6ms preprocess, 809.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_453 (2).jpg: 384x640 10 cars, 4 trucks, 964.1ms\n",
            "Speed: 3.4ms preprocess, 964.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_349.jpg: 384x640 4 persons, 1 bus, 2 trains, 2 trucks, 1275.8ms\n",
            "Speed: 2.7ms preprocess, 1275.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_341 (3).jpg: 448x640 8 cars, 1493.0ms\n",
            "Speed: 3.1ms preprocess, 1493.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_408.jpg: 320x640 2 persons, 18 cars, 1 bus, 1146.2ms\n",
            "Speed: 2.4ms preprocess, 1146.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_316.jpg: 416x640 9 cars, 2 buss, 1 truck, 996.1ms\n",
            "Speed: 3.6ms preprocess, 996.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_352 (3).jpg: 320x640 3 persons, 13 cars, 1 truck, 1 handbag, 662.0ms\n",
            "Speed: 1.7ms preprocess, 662.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_522 (2).jpg: 448x640 5 cars, 931.3ms\n",
            "Speed: 3.0ms preprocess, 931.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_537 (2).jpg: 384x640 7 persons, 3 cars, 1 train, 3 trucks, 804.9ms\n",
            "Speed: 2.3ms preprocess, 804.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_268 (3).jpg: 384x640 8 cars, 1 traffic light, 799.0ms\n",
            "Speed: 2.8ms preprocess, 799.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_525 (2).jpg: 640x480 (no detections), 999.2ms\n",
            "Speed: 3.2ms preprocess, 999.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_633.jpg: 480x640 2 persons, 2 bicycles, 10 cars, 2 buss, 1 truck, 986.6ms\n",
            "Speed: 3.6ms preprocess, 986.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_653 (2).jpg: 384x640 1 person, 12 cars, 1 truck, 810.7ms\n",
            "Speed: 2.7ms preprocess, 810.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_544.jpg: 480x640 10 cars, 9 buss, 3 traffic lights, 999.3ms\n",
            "Speed: 3.2ms preprocess, 999.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_610.jpg: 416x640 7 persons, 4 cars, 3 buss, 858.7ms\n",
            "Speed: 3.0ms preprocess, 858.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_597.jpg: 640x544 2 cars, 2 buss, 1142.5ms\n",
            "Speed: 3.6ms preprocess, 1142.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_575 (2).jpg: 352x640 20 cars, 1 truck, 1192.6ms\n",
            "Speed: 2.8ms preprocess, 1192.6ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_564.jpg: 480x640 7 persons, 6 cars, 2 trucks, 1829.0ms\n",
            "Speed: 4.3ms preprocess, 1829.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_576.jpg: 448x640 13 cars, 1 truck, 1 traffic light, 1628.5ms\n",
            "Speed: 3.1ms preprocess, 1628.5ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_551 (2).jpg: 480x640 1 person, 8 cars, 1 traffic light, 1830.8ms\n",
            "Speed: 3.3ms preprocess, 1830.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_640.jpg: 384x640 11 cars, 3 trucks, 1601.0ms\n",
            "Speed: 2.7ms preprocess, 1601.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_564 (2).jpg: 384x640 13 cars, 1020.0ms\n",
            "Speed: 2.9ms preprocess, 1020.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_551 (4).jpg: 320x640 5 cars, 1 truck, 672.8ms\n",
            "Speed: 2.6ms preprocess, 672.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_654.jpg: 480x640 4 cars, 3 trucks, 994.6ms\n",
            "Speed: 3.2ms preprocess, 994.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_649 (2).jpg: 448x640 14 cars, 922.3ms\n",
            "Speed: 3.5ms preprocess, 922.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_649.jpg: 384x640 8 persons, 6 cars, 3 motorcycles, 5 buss, 2 trucks, 811.8ms\n",
            "Speed: 2.7ms preprocess, 811.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_697.jpg: 416x640 6 cars, 6 buss, 1 truck, 1 traffic light, 861.0ms\n",
            "Speed: 3.0ms preprocess, 861.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_658 (2).jpg: 384x640 8 cars, 5 traffic lights, 795.9ms\n",
            "Speed: 2.7ms preprocess, 795.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_662 (2).jpg: 416x640 13 cars, 3 trucks, 1 dog, 864.1ms\n",
            "Speed: 3.2ms preprocess, 864.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_712 (2).jpg: 480x640 (no detections), 984.2ms\n",
            "Speed: 3.2ms preprocess, 984.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_554 (2).jpg: 448x640 8 cars, 1 truck, 949.6ms\n",
            "Speed: 3.1ms preprocess, 949.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_663 (2).jpg: 640x640 11 cars, 1549.1ms\n",
            "Speed: 3.3ms preprocess, 1549.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_615.jpg: 480x640 1 person, 7 cars, 1 truck, 1564.7ms\n",
            "Speed: 3.4ms preprocess, 1564.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_651.jpg: 448x640 1 person, 14 cars, 4 buss, 1491.0ms\n",
            "Speed: 3.2ms preprocess, 1491.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_631.jpg: 512x640 3 persons, 14 cars, 1 motorcycle, 3 buss, 1 truck, 1461.8ms\n",
            "Speed: 3.3ms preprocess, 1461.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_678.jpg: 480x640 13 cars, 5 trucks, 988.8ms\n",
            "Speed: 2.3ms preprocess, 988.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_549.jpg: 448x640 1 person, 7 cars, 1 motorcycle, 2 buss, 3 trucks, 934.3ms\n",
            "Speed: 3.2ms preprocess, 934.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_801.jpg: 480x640 2 persons, 18 cars, 2 traffic lights, 987.4ms\n",
            "Speed: 3.0ms preprocess, 987.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_637.jpg: 448x640 12 cars, 1 truck, 7 traffic lights, 925.9ms\n",
            "Speed: 2.2ms preprocess, 925.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_644.jpg: 384x640 8 cars, 4 buss, 795.3ms\n",
            "Speed: 3.0ms preprocess, 795.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_624.jpg: 416x640 17 cars, 1 bus, 4 trucks, 867.2ms\n",
            "Speed: 3.1ms preprocess, 867.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_667 (2).jpg: 640x384 8 cars, 1 bus, 842.6ms\n",
            "Speed: 2.9ms preprocess, 842.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_771.jpg: 416x640 1 person, 13 cars, 2 buss, 871.0ms\n",
            "Speed: 2.7ms preprocess, 871.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_673 (3).jpg: 448x640 8 cars, 1 truck, 956.4ms\n",
            "Speed: 3.0ms preprocess, 956.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_606.jpg: 384x640 1 person, 15 cars, 4 buss, 4 trucks, 842.5ms\n",
            "Speed: 2.8ms preprocess, 842.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_569.jpg: 448x640 5 cars, 3 buss, 1 truck, 1283.6ms\n",
            "Speed: 2.6ms preprocess, 1283.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_585.jpg: 384x640 10 cars, 3 buss, 1 truck, 1299.9ms\n",
            "Speed: 2.8ms preprocess, 1299.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_717.jpg: 384x640 7 cars, 3 buss, 1317.5ms\n",
            "Speed: 2.8ms preprocess, 1317.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_584.jpg: 640x640 12 cars, 2 buss, 2 trucks, 1771.3ms\n",
            "Speed: 4.2ms preprocess, 1771.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_560 (2).jpg: 384x640 2 persons, 13 cars, 1 truck, 817.9ms\n",
            "Speed: 3.1ms preprocess, 817.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_579 (2).jpg: 416x640 1 person, 6 cars, 7 buss, 854.1ms\n",
            "Speed: 2.1ms preprocess, 854.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_638.jpg: 448x640 3 persons, 12 cars, 6 buss, 5 trucks, 929.5ms\n",
            "Speed: 3.2ms preprocess, 929.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_549 (2).jpg: 448x640 14 cars, 4 trucks, 936.6ms\n",
            "Speed: 4.2ms preprocess, 936.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_667.jpg: 384x640 (no detections), 817.8ms\n",
            "Speed: 2.4ms preprocess, 817.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_713.jpg: 384x640 1 person, 8 cars, 2 buss, 4 trucks, 800.9ms\n",
            "Speed: 2.9ms preprocess, 800.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_616.jpg: 480x640 7 cars, 4 buss, 2 trucks, 1002.2ms\n",
            "Speed: 3.1ms preprocess, 1002.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_810.jpg: 352x640 3 persons, 14 cars, 2 motorcycles, 2 trucks, 740.7ms\n",
            "Speed: 3.2ms preprocess, 740.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_616 (2).jpg: 384x640 1 person, 3 cars, 1 bus, 3 trains, 2 trucks, 805.6ms\n",
            "Speed: 2.5ms preprocess, 805.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_721.jpg: 384x640 13 cars, 1 truck, 798.3ms\n",
            "Speed: 4.3ms preprocess, 798.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_679 (2).jpg: 352x640 13 cars, 1 bus, 832.3ms\n",
            "Speed: 2.2ms preprocess, 832.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_629.jpg: 384x640 10 cars, 4 buss, 1284.0ms\n",
            "Speed: 2.7ms preprocess, 1284.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_602.jpg: 448x640 9 cars, 5 buss, 2 trucks, 1519.4ms\n",
            "Speed: 3.2ms preprocess, 1519.4ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_652.jpg: 320x640 1 person, 6 cars, 5 buss, 4 trucks, 1090.3ms\n",
            "Speed: 2.4ms preprocess, 1090.3ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_546 (2).jpg: 384x640 18 cars, 1 bus, 1043.6ms\n",
            "Speed: 2.7ms preprocess, 1043.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_649 (3).jpg: 448x640 1 person, 12 cars, 1 truck, 923.4ms\n",
            "Speed: 2.5ms preprocess, 923.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_594 (3).jpg: 384x640 6 persons, 13 cars, 5 trucks, 1 umbrella, 812.9ms\n",
            "Speed: 3.7ms preprocess, 812.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_589.jpg: 448x640 10 persons, 1 bicycle, 9 cars, 1 bus, 1 truck, 933.6ms\n",
            "Speed: 3.2ms preprocess, 933.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_681.jpg: 352x640 2 persons, 5 cars, 1 bus, 1 truck, 760.8ms\n",
            "Speed: 2.7ms preprocess, 760.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_672.jpg: 640x448 2 persons, 10 cars, 2 motorcycles, 2 buss, 1 truck, 975.2ms\n",
            "Speed: 2.3ms preprocess, 975.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_776.jpg: 384x640 16 cars, 4 buss, 1 traffic light, 799.0ms\n",
            "Speed: 3.1ms preprocess, 799.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_645.jpg: 384x640 16 cars, 806.7ms\n",
            "Speed: 2.7ms preprocess, 806.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_642 (2).jpg: 448x640 1 person, 10 cars, 1 bus, 951.2ms\n",
            "Speed: 3.2ms preprocess, 951.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_548 (2).jpg: 384x640 19 cars, 6 trucks, 810.7ms\n",
            "Speed: 2.7ms preprocess, 810.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_797.jpg: 480x640 5 cars, 1020.4ms\n",
            "Speed: 3.3ms preprocess, 1020.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_590.jpg: 640x448 11 cars, 1 bus, 2 trucks, 1245.6ms\n",
            "Speed: 3.1ms preprocess, 1245.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_605 (2).jpg: 448x640 4 persons, 5 cars, 3 buss, 5 trucks, 1518.5ms\n",
            "Speed: 3.1ms preprocess, 1518.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_710.jpg: 448x640 1 car, 1497.2ms\n",
            "Speed: 3.3ms preprocess, 1497.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_635 (2).jpg: 448x640 2 persons, 16 cars, 1 motorcycle, 1 bus, 3 trucks, 1284.7ms\n",
            "Speed: 3.3ms preprocess, 1284.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_646 (2).jpg: 384x640 1 person, 15 cars, 1 bus, 2 trucks, 805.0ms\n",
            "Speed: 2.8ms preprocess, 805.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_692 (2).jpg: 352x640 2 persons, 6 cars, 3 buss, 1 truck, 1 boat, 739.1ms\n",
            "Speed: 3.1ms preprocess, 739.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_621.jpg: 640x640 (no detections), 1362.6ms\n",
            "Speed: 4.3ms preprocess, 1362.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_725 (2).jpg: 448x640 5 persons, 7 cars, 5 buss, 1 truck, 917.2ms\n",
            "Speed: 2.3ms preprocess, 917.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_666.jpg: 384x640 1 person, 5 buss, 1 truck, 806.5ms\n",
            "Speed: 3.0ms preprocess, 806.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_611 (2).jpg: 576x640 6 cars, 2 trucks, 1186.3ms\n",
            "Speed: 3.9ms preprocess, 1186.3ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_630.jpg: 416x640 (no detections), 871.9ms\n",
            "Speed: 2.9ms preprocess, 871.9ms inference, 0.7ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_684.jpg: 416x640 6 cars, 4 buss, 1 truck, 865.2ms\n",
            "Speed: 3.0ms preprocess, 865.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_695.jpg: 384x640 3 cars, 1 truck, 792.2ms\n",
            "Speed: 2.9ms preprocess, 792.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_726.jpg: 384x640 16 cars, 1 truck, 809.6ms\n",
            "Speed: 2.8ms preprocess, 809.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_581.jpg: 448x640 (no detections), 1359.6ms\n",
            "Speed: 3.3ms preprocess, 1359.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_573.jpg: 448x640 1 person, 7 cars, 1 bus, 1505.8ms\n",
            "Speed: 9.2ms preprocess, 1505.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_598.jpg: 416x640 2 persons, 1 car, 10 buss, 3 trucks, 1426.5ms\n",
            "Speed: 3.0ms preprocess, 1426.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_650.jpg: 448x640 17 cars, 6 trucks, 1159.7ms\n",
            "Speed: 3.8ms preprocess, 1159.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_675 (2).jpg: 448x640 1 person, 9 cars, 1 bus, 1 handbag, 943.8ms\n",
            "Speed: 3.1ms preprocess, 943.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_543 (3).jpg: 448x640 17 cars, 2 buss, 927.3ms\n",
            "Speed: 3.2ms preprocess, 927.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_690 (2).jpg: 384x640 9 cars, 823.3ms\n",
            "Speed: 2.7ms preprocess, 823.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_720 (2).jpg: 448x640 3 cars, 940.2ms\n",
            "Speed: 2.8ms preprocess, 940.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_665.jpg: 384x640 3 persons, 7 cars, 1 bus, 1 truck, 808.8ms\n",
            "Speed: 2.6ms preprocess, 808.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_575 (3).jpg: 448x640 4 persons, 12 cars, 1 train, 2 trucks, 953.1ms\n",
            "Speed: 3.1ms preprocess, 953.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_798.jpg: 480x640 8 persons, 4 cars, 7 motorcycles, 1 umbrella, 998.6ms\n",
            "Speed: 3.3ms preprocess, 998.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_597 (2).jpg: 384x640 1 person, 8 cars, 3 buss, 1 truck, 809.4ms\n",
            "Speed: 2.8ms preprocess, 809.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_578.jpg: 384x640 5 trains, 4 trucks, 800.6ms\n",
            "Speed: 2.0ms preprocess, 800.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_642 (4).jpg: 448x640 2 persons, 7 cars, 2 buss, 938.3ms\n",
            "Speed: 3.5ms preprocess, 938.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_618 (3).jpg: 480x640 2 cars, 1451.5ms\n",
            "Speed: 2.8ms preprocess, 1451.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_560 (3).jpg: 384x640 12 cars, 1 truck, 1298.3ms\n",
            "Speed: 2.7ms preprocess, 1298.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_601 (2).jpg: 384x640 1 bus, 1303.6ms\n",
            "Speed: 2.9ms preprocess, 1303.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_700.jpg: 352x640 11 cars, 1 truck, 1156.4ms\n",
            "Speed: 2.5ms preprocess, 1156.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_731.jpg: 384x640 2 cars, 5 buss, 3 trucks, 810.2ms\n",
            "Speed: 2.6ms preprocess, 810.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_712.jpg: 448x640 2 persons, 1 bicycle, 9 cars, 1 truck, 1 traffic light, 1 backpack, 939.7ms\n",
            "Speed: 3.3ms preprocess, 939.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_575.jpg: 384x640 10 persons, 15 cars, 2 motorcycles, 3 buss, 2 trucks, 1 traffic light, 807.7ms\n",
            "Speed: 2.7ms preprocess, 807.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_748.jpg: 416x640 1 person, 15 cars, 3 buss, 2 trucks, 872.9ms\n",
            "Speed: 2.9ms preprocess, 872.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_796.jpg: 384x640 6 cars, 10 buss, 4 trucks, 818.3ms\n",
            "Speed: 2.8ms preprocess, 818.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_596 (2).jpg: 352x640 1 person, 1 car, 2 buss, 3 trucks, 737.4ms\n",
            "Speed: 2.5ms preprocess, 737.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_702.jpg: 384x640 8 cars, 2 buss, 1 truck, 807.0ms\n",
            "Speed: 2.4ms preprocess, 807.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_555 (2).jpg: 416x640 11 cars, 6 trucks, 864.4ms\n",
            "Speed: 3.2ms preprocess, 864.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_607.jpg: 640x448 10 cars, 943.6ms\n",
            "Speed: 3.5ms preprocess, 943.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_678 (3).jpg: 480x640 1 person, 9 cars, 6 buss, 1 truck, 1 clock, 1011.3ms\n",
            "Speed: 3.5ms preprocess, 1011.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_612.jpg: 384x640 11 cars, 2 buss, 825.5ms\n",
            "Speed: 2.5ms preprocess, 825.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_657.jpg: 384x640 1 person, 10 cars, 2 buss, 1 umbrella, 1093.3ms\n",
            "Speed: 2.8ms preprocess, 1093.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_643 (2).jpg: 480x640 7 cars, 1586.7ms\n",
            "Speed: 3.4ms preprocess, 1586.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_562 (3).jpg: 480x640 1 person, 11 buss, 2 trucks, 1 umbrella, 1621.2ms\n",
            "Speed: 3.5ms preprocess, 1621.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_579 (3).jpg: 448x640 8 cars, 1 truck, 1190.0ms\n",
            "Speed: 3.1ms preprocess, 1190.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_769.jpg: 448x640 2 persons, 22 cars, 2 buss, 1 truck, 941.3ms\n",
            "Speed: 3.2ms preprocess, 941.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_565 (2).jpg: 384x640 5 cars, 821.7ms\n",
            "Speed: 2.8ms preprocess, 821.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_698.jpg: 480x640 3 persons, 12 cars, 6 buss, 2 trucks, 1020.3ms\n",
            "Speed: 3.4ms preprocess, 1020.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_572 (2).jpg: 448x640 11 cars, 1 truck, 957.0ms\n",
            "Speed: 3.3ms preprocess, 957.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_765.jpg: 384x640 12 cars, 6 buss, 1 truck, 805.6ms\n",
            "Speed: 3.0ms preprocess, 805.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_681 (2).jpg: 448x640 5 persons, 5 cars, 4 buss, 938.2ms\n",
            "Speed: 2.9ms preprocess, 938.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_676 (2).jpg: 640x416 6 cars, 1 truck, 894.4ms\n",
            "Speed: 3.3ms preprocess, 894.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_595 (2).jpg: 384x640 15 cars, 815.3ms\n",
            "Speed: 5.9ms preprocess, 815.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_653.jpg: 448x640 15 cars, 1 truck, 949.4ms\n",
            "Speed: 2.9ms preprocess, 949.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_583 (2).jpg: 352x640 6 persons, 3 cars, 2 buss, 1 truck, 758.9ms\n",
            "Speed: 2.7ms preprocess, 758.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_547.jpg: 576x640 3 cars, 1 bus, 3 trucks, 1685.7ms\n",
            "Speed: 4.6ms preprocess, 1685.7ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_577.jpg: 448x640 7 cars, 1 truck, 1509.1ms\n",
            "Speed: 5.2ms preprocess, 1509.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_605.jpg: 384x640 2 persons, 9 cars, 3 buss, 6 trucks, 1324.7ms\n",
            "Speed: 2.9ms preprocess, 1324.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_711.jpg: 384x640 (no detections), 1038.7ms\n",
            "Speed: 2.8ms preprocess, 1038.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_671.jpg: 416x640 5 cars, 859.6ms\n",
            "Speed: 3.0ms preprocess, 859.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_544 (2).jpg: 320x640 1 car, 2 buss, 4 trains, 4 trucks, 681.9ms\n",
            "Speed: 2.6ms preprocess, 681.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_546.jpg: 352x640 8 persons, 13 cars, 1 motorcycle, 742.2ms\n",
            "Speed: 2.9ms preprocess, 742.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_642.jpg: 384x640 14 cars, 1 truck, 798.0ms\n",
            "Speed: 3.5ms preprocess, 798.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_607 (2).jpg: 384x640 16 cars, 6 buss, 809.3ms\n",
            "Speed: 2.8ms preprocess, 809.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_678 (2).jpg: 384x640 5 cars, 2 buss, 5 trucks, 807.2ms\n",
            "Speed: 2.7ms preprocess, 807.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_572.jpg: 416x640 11 persons, 1 bicycle, 6 cars, 3 motorcycles, 1 truck, 2 traffic lights, 1 backpack, 851.5ms\n",
            "Speed: 3.1ms preprocess, 851.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_682.jpg: 416x640 4 persons, 14 cars, 1 bus, 4 trucks, 851.9ms\n",
            "Speed: 2.9ms preprocess, 851.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_543.jpg: 384x640 4 persons, 14 cars, 2 buss, 814.8ms\n",
            "Speed: 2.7ms preprocess, 814.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_670.jpg: 320x640 3 persons, 13 cars, 1 truck, 1 handbag, 669.0ms\n",
            "Speed: 2.4ms preprocess, 669.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_600.jpg: 512x640 5 persons, 3 cars, 2 trucks, 1 traffic light, 1072.5ms\n",
            "Speed: 3.6ms preprocess, 1072.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_565.jpg: 416x640 6 persons, 3 cars, 3 buss, 1 train, 2 trucks, 1138.7ms\n",
            "Speed: 3.4ms preprocess, 1138.7ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_550 (2).jpg: 288x640 6 cars, 5 buss, 1 truck, 991.4ms\n",
            "Speed: 2.2ms preprocess, 991.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_702 (2).jpg: 384x640 6 cars, 4 traffic lights, 1288.9ms\n",
            "Speed: 2.9ms preprocess, 1288.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_618 (2).jpg: 384x640 1 person, 12 cars, 1 truck, 1355.3ms\n",
            "Speed: 2.8ms preprocess, 1355.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_610 (2).jpg: 384x640 1 person, 1 car, 6 trucks, 865.1ms\n",
            "Speed: 2.7ms preprocess, 865.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_723.jpg: 352x640 12 cars, 4 trucks, 746.6ms\n",
            "Speed: 2.4ms preprocess, 746.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_599 (2).jpg: 384x640 6 cars, 1 truck, 4 traffic lights, 807.6ms\n",
            "Speed: 2.7ms preprocess, 807.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_559 (2).jpg: 384x640 7 cars, 2 buss, 4 trucks, 813.6ms\n",
            "Speed: 2.8ms preprocess, 813.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_664 (2).jpg: 384x640 2 persons, 4 cars, 1 bus, 5 trucks, 808.7ms\n",
            "Speed: 2.9ms preprocess, 808.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_631 (2).jpg: 480x640 16 cars, 1 bus, 1 truck, 1004.7ms\n",
            "Speed: 3.6ms preprocess, 1004.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_551.jpg: 384x640 14 cars, 2 trucks, 805.7ms\n",
            "Speed: 2.6ms preprocess, 805.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_553.jpg: 480x640 1 person, 12 cars, 6 buss, 1 truck, 1009.0ms\n",
            "Speed: 2.3ms preprocess, 1009.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_752.jpg: 480x640 17 cars, 1 bus, 2 trucks, 1018.8ms\n",
            "Speed: 3.3ms preprocess, 1018.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_641.jpg: 384x640 16 cars, 6 buss, 813.8ms\n",
            "Speed: 2.8ms preprocess, 813.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_719.jpg: 384x640 6 cars, 2 buss, 1 truck, 8 traffic lights, 803.7ms\n",
            "Speed: 2.7ms preprocess, 803.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_725.jpg: 320x640 2 persons, 7 cars, 1 truck, 806.4ms\n",
            "Speed: 2.5ms preprocess, 806.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_620.jpg: 544x640 14 cars, 1803.9ms\n",
            "Speed: 6.1ms preprocess, 1803.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_580.jpg: 448x640 1 car, 1 bus, 1 truck, 1 traffic light, 1535.0ms\n",
            "Speed: 3.1ms preprocess, 1535.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_562 (2).jpg: 448x640 5 cars, 4 trucks, 1362.1ms\n",
            "Speed: 3.1ms preprocess, 1362.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_554.jpg: 480x640 14 cars, 1 bus, 2 trucks, 1019.5ms\n",
            "Speed: 3.4ms preprocess, 1019.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_557.jpg: 448x640 14 cars, 10 buss, 937.9ms\n",
            "Speed: 2.4ms preprocess, 937.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_680 (2).jpg: 416x640 (no detections), 865.1ms\n",
            "Speed: 3.3ms preprocess, 865.1ms inference, 0.7ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_733.jpg: 384x640 1 train, 1 keyboard, 809.5ms\n",
            "Speed: 4.3ms preprocess, 809.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_742.jpg: 640x640 16 cars, 1 bus, 2 trucks, 1361.0ms\n",
            "Speed: 4.5ms preprocess, 1361.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_703.jpg: 352x640 1 person, 12 cars, 3 buss, 1 truck, 741.5ms\n",
            "Speed: 4.2ms preprocess, 741.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_541.jpg: 480x640 18 cars, 992.8ms\n",
            "Speed: 4.0ms preprocess, 992.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_555.jpg: 352x640 6 persons, 4 cars, 738.8ms\n",
            "Speed: 2.4ms preprocess, 738.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_594 (2).jpg: 352x640 4 persons, 5 cars, 4 buss, 2 trucks, 738.3ms\n",
            "Speed: 2.2ms preprocess, 738.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_703 (2).jpg: 416x640 3 buss, 3 trains, 3 trucks, 875.1ms\n",
            "Speed: 3.0ms preprocess, 875.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_785.jpg: 480x640 15 cars, 2 buss, 3 traffic lights, 1398.7ms\n",
            "Speed: 4.2ms preprocess, 1398.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Colab Notebooks/dense_traffic/images_601.jpg: 448x640 10 cars, 1 bus, 1 truck, 1512.2ms\n",
            "Speed: 5.4ms preprocess, 1512.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-0f76428e46ad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check for image files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Perform object detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \"\"\"\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m  \u001b[0;31m# yield embedding tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/autobackend.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# PyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# TorchScript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Training path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_fuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;34m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Process the results (e.g., display or save)\n",
        "  print(results)  # Print the detection results\n",
        ""
      ],
      "metadata": {
        "id": "lsExOCzSnqV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ByMCtX0dowfn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}